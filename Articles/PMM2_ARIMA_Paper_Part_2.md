### 2.5. Дизайн Monte Carlo експерименту

**2.5.1. Цілі симуляційного дослідження**

Monte Carlo експерименти проводяться для:
1. Валідації асимптотичних результатів на скінченних вибірках
2. Порівняння PMM2 з класичними методами (CSS, OLS)
3. Дослідження впливу розміру вибірки
4. Аналізу ефективності для різних розподілів інновацій

**2.5.2. Параметри симуляцій**

**Моделі:**
Основна увага приділяється простішому випадку для чистоти експерименту:
- **ARIMA(1,1,0):** $\Delta y_t = \phi_1 \Delta y_{t-1} + \varepsilon_t$ з $\phi_1 = 0.5$

**Розміри вибірки:**
$$N \in \{100, 200, 500, 1000\}$$

**Розподіли інновацій:**

1. **Gaussian (контроль):**
   $$\varepsilon_t \sim \mathcal{N}(0, 1)$$
   Параметри: $\gamma_3 = 0$, $\gamma_4 = 0$

2. **Gamma(2,1) - помірна асиметрія:**
   $$\varepsilon_t \sim \Gamma(2, 1) - 2$$
   Теоретичні параметри: $\gamma_3 \approx 1.41$, $\gamma_4 \approx 3.0$

3. **Lognormal - сильна асиметрія:**
   $$\varepsilon_t \sim \text{LogNormal}(0, 0.5) - \text{mean}$$
   Теоретичні параметри: $\gamma_3 \approx 2.0$, $\gamma_4 \approx 6.0$

4. **Chi-squared(3) - помірна асиметрія:**
   $$\varepsilon_t \sim \chi^2(3) - 3$$
   Теоретичні параметри: $\gamma_3 \approx 1.63$, $\gamma_4 \approx 4.0$

Всі розподіли центруються (віднімається середнє) для забезпечення $E[\varepsilon_t] = 0$.

**Кількість повторень:**
$$M = 2000 \text{ симуляцій на кожну конфігурацію}$$

Загальна кількість симуляцій: $4 \text{ розподіли} \times 4 \text{ розміри} \times 2000 = 32,000$.

**2.5.3. Процедура генерації даних**

Для кожної симуляції $m = 1, \ldots, M$:

1. **Генерація інновацій:**
   Згенерувати $\{\varepsilon_t^{(m)}\}_{t=1}^{N}$ з обраного розподілу та центрувати.

2. **Генерація AR(1) процесу:**
   Використовуючи стаціонарну ініціалізацію:
   $$x_0^{(m)} \sim \mathcal{N}\left(0, \frac{\sigma^2}{1-\phi_1^2}\right)$$
   
   Рекурсивно:
   $$x_t^{(m)} = \phi_1 x_{t-1}^{(m)} + \varepsilon_t^{(m)}, \quad t = 1, \ldots, N$$

3. **Інтегрування (для d=1):**
   $$y_t^{(m)} = \sum_{k=1}^{t} x_k^{(m)}$$

**2.5.4. Оцінювання та метрики**

Для кожної симуляції:

1. **CSS оцінка:** $\hat{\phi}_{CSS}^{(m)}$
2. **PMM2 оцінка:** $\hat{\phi}_{PMM2}^{(m)}$

**Обчислювані статистики (по M симуляціях):**

**Зміщення (Bias):**
$$\text{Bias}(\hat{\phi}) = \frac{1}{M}\sum_{m=1}^{M} \hat{\phi}^{(m)} - \phi_0$$

**Дисперсія:**
$$\text{Var}(\hat{\phi}) = \frac{1}{M-1}\sum_{m=1}^{M} \left(\hat{\phi}^{(m)} - \overline{\hat{\phi}}\right)^2$$

де $\overline{\hat{\phi}} = \frac{1}{M}\sum_{m=1}^{M} \hat{\phi}^{(m)}$.

**Середньоквадратична похибка (MSE):**
$$\text{MSE}(\hat{\phi}) = \text{Bias}^2(\hat{\phi}) + \text{Var}(\hat{\phi})$$

**Відносна ефективність (емпірична):**
$$\widehat{RE} = \frac{\text{Var}(\hat{\phi}_{CSS})}{\text{Var}(\hat{\phi}_{PMM2})}$$

**Відсоток зменшення дисперсії:**
$$\text{VarRed\%} = \left(1 - \frac{\text{Var}(\hat{\phi}_{PMM2})}{\text{Var}(\hat{\phi}_{CSS})}\right) \times 100\%$$

**2.5.5. Програмна імплементація**

Всі симуляції проведено в Python 3.9+ з використанням бібліотек:
- **NumPy 1.24+** - числові обчислення
- **SciPy 1.10+** - оптимізація та статистичні розподіли
- **statsmodels 0.14+** - ADF тест та порівняння з класичними методами
- **pandas 2.0+** - управління даними
- **matplotlib/seaborn** - візуалізація

Код доступний у відкритому доступі для забезпечення відтворюваності результатів.

---

## 3. ЕМПІРИЧНІ РЕЗУЛЬТАТИ

### 3.1. Валідація імплементації

**3.1.1. Тестовий приклад**

Для валідації коректності імплементації спочатку розглянемо одну типову симуляцію.

**Параметри:**
- Модель: ARIMA(1,1,0) з $\phi_1 = 0.5$
- Розмір вибірки: $N = 500$
- Інновації: Gamma(2,1)
- Seed: 42 (для відтворюваності)

**Результати:**

| Метод | $\hat{\phi}_1$ | Ітерації | Збіжність |
|-------|----------------|----------|-----------|
| CSS   | 0.4756         | -        | ✓         |
| PMM2  | 0.4768         | 3        | ✓         |

**Статистики залишків:**
- Коефіцієнт асиметрії: $\hat{\gamma}_3 = 1.24$
- Коефіцієнт ексцесу: $\hat{\gamma}_4 = 1.65$
- Variance CSS: 0.00148
- Variance PMM2: 0.00148
- Теоретичний $g$: 0.577

**Висновок:** Алгоритм збігається швидко (3 ітерації) і дає оцінки близькі до істинного значення $\phi_1 = 0.5$.

### 3.2. Основні результати Monte Carlo

**3.2.1. Порівняння для різних розподілів (N=500)**

Таблиця 1 представляє основні результаті 2000 симуляцій для розміру вибірки $N=500$.

**Таблиця 1.** Результати Monte Carlo для ARIMA(1,1,0) моделі: порівняння CSS та PMM2

| Розподіл       | $\overline{\gamma_3}$ | Метод | Bias      | Var       | MSE       | RE    |
|----------------|-----------------------|-------|-----------|-----------|-----------|-------|
| **Gaussian**   | -0.01                 | CSS   | -0.0112   | 0.003897  | 0.004023  | 0.99  |
|                |                       | PMM2  | -0.0119   | 0.003923  | 0.004065  |       |
| **Gamma(2,1)** | 1.35                  | CSS   | -0.0115   | 0.003620  | 0.003752  | **1.62** |
|                |                       | PMM2  | -0.0080   | 0.002233  | 0.002297  |       |
| **Lognormal**  | 1.46                  | CSS   | -0.0106   | 0.003771  | 0.003883  | **1.71** |
|                |                       | PMM2  | -0.0071   | 0.002206  | 0.002256  |       |
| **Chi-sq(3)**  | 1.45                  | CSS   | -0.0121   | 0.003758  | 0.003904  | **1.87** |
|                |                       | PMM2  | -0.0068   | 0.002010  | 0.002056  |       |

**Ключові спостереження:**

1. **Gaussian baseline:** Для нормального розподілу ($\gamma_3 \approx 0$) PMM2 та CSS дають практично ідентичні результати (RE ≈ 1.0), що узгоджується з теорією.

2. **Суттєва перевага PMM2:** Для асиметричних розподілів ($|\gamma_3| > 1$) PMM2 демонструє:
   - **40-47% зменшення MSE**
   - **Відносна ефективність 1.62-1.87**
   - Менше зміщення в більшості випадків

3. **Зв'язок з асиметрією:** Ефективність PMM2 корелює з величиною $|\gamma_3|$: чим більша асиметрія, тим більша перевага.

**3.2.2. Відповідність теоретичним передбаченням**

Таблиця 2 порівнює емпіричну відносну ефективність з теоретичними передбаченнями.

**Таблиця 2.** Теоретична vs Емпірична відносна ефективність (N=500)

| Розподіл       | $\gamma_3$ | $\gamma_4$ | $RE_{theory}$ | $RE_{empirical}$ | Різниця |
|----------------|------------|------------|---------------|------------------|---------|
| Gaussian       | 0.00       | 0.00       | 1.00          | 0.99             | -0.01   |
| Gamma(2,1)     | 1.41       | 3.00       | 1.66          | 1.62             | -0.04   |
| Lognormal      | 2.00       | 6.00       | 2.00          | 1.71             | -0.29   |
| Chi-squared(3) | 1.63       | 4.00       | 1.79          | 1.87             | +0.08   |

де теоретична RE обчислюється за формулою:
$$RE_{theory} = \frac{1}{1 - \frac{\gamma_3^2}{2 + \gamma_4}}$$

**Інтерпретація:**

- Емпіричні результати **добре узгоджуються** з теоретичними передбаченнями (середнє абсолютне відхилення: 0.10)
- Для Lognormal розподілу емпірична RE дещо нижча за теоретичну, що може бути пов'язано з важкими хвостами та скінченою вибіркою
- Загалом, **теорія підтверджується** емпірично

### 3.3. Вплив розміру вибірки

**3.3.1. Збіжність до асимптотичних властивостей**

Таблиця 3 показує як змінюються статистики зі збільшенням розміру вибірки для Gamma(2,1) інновацій.

**Таблиця 3.** Вплив розміру вибірки на ефективність PMM2 (Gamma(2,1) інновації)

| N    | CSS Var | PMM2 Var | MSE_CSS  | MSE_PMM2 | RE   | VarRed% | Conv.Rate |
|------|---------|----------|----------|----------|------|---------|-----------|
| 100  | 0.00801 | 0.00457  | 0.00801  | 0.00457  | 1.70 | 41.2%   | 96.2%     |
| 200  | 0.00377 | 0.00227  | 0.00377  | 0.00227  | 1.63 | 38.7%   | 98.7%     |
| 500  | 0.00144 | 0.00089  | 0.00144  | 0.00089  | 1.62 | 38.2%   | 99.8%     |
| 1000 | 0.00076 | 0.00045  | 0.00076  | 0.00045  | 1.67 | 40.1%   | 99.9%     |

**Ключові висновки:**

1. **Стабільність при N ≥ 200:** RE стабілізується на рівні 1.62-1.67 для вибірок від 200 спостережень.

2. **Зменшення дисперсії:** Для всіх розмірів вибірки PMM2 досягає стабільних **38-41% зменшення дисперсії**.

3. **Надійність збіжності:** Алгоритм PMM2 досягає збіжності в 96-100% випадків, причому надійність зростає з розміром вибірки.

4. **Малі вибірки:** Навіть для N=100 PMM2 демонструє суттєві переваги (RE=1.70), хоча з дещо нижчою надійністю.

**3.3.2. Графічний аналіз**

Рисунок 1 (figure1_distributions.png) показує порівняння чотирьох розподілів інновацій з накладеною стандартною нормальною кривою.

**Рисунок 1.** Порівняння розподілів інновацій

[Див. figure1_distributions.png]

**Спостереження:**
- Gamma, Lognormal та Chi-squared розподіли демонструють помітну правостороннюю асиметрію
- Gaussian розподіл (контроль) є симетричним
- Всі розподіли стандартизовано для порівнянності

---

Рисунок 2 (figure2_efficiency.png) демонструє як відносна ефективність та зменшення MSE змінюються з розміром вибірки.

**Рисунок 2.** Відносна ефективність та MSE reduction vs розмір вибірки

[Див. figure2_efficiency.png]

**Ліва панель (RE vs N):**
- RE стабілізується при N ≥ 200
- Gamma, Lognormal та Chi-squared показують RE > 1.5
- Gaussian залишається на рівні RE ≈ 1.0

**Права панель (MSE Reduction %):**
- Стійкі 35-50% покращення для асиметричних розподілів
- Покращення зберігається для всіх розмірів вибірки
- Найбільше покращення для Chi-squared (до 48%)

---

Рисунок 3 (figure3_theory_vs_empirical.png) порівнює теоретичні та емпіричні значення відносної ефективності.

**Рисунок 3.** Теоретична vs Емпірична відносна ефективність

[Див. figure3_theory_vs_empirical.png]

**Спостереження:**
- Емпіричні значення (помаранчеві) близькі до теоретичних (блакитні)
- Для Gamma та Chi-squared відмінність < 10%
- Підтверджує валідність теоретичних результатів Кунченко

### 3.4. Розподіл оцінок параметрів

**3.4.1. Гістограми оцінок**

Для детального аналізу розглянемо розподіли оцінок $\hat{\phi}_1$ з 2000 симуляцій для Gamma(2,1) інновацій при N=500.

**Таблиця 4.** Статистичний опис розподілу оцінок (Gamma, N=500)

| Метод | Mean   | Median | Std    | Q1     | Q3     | IQR    |
|-------|--------|--------|--------|--------|--------|--------|
| CSS   | 0.4888 | 0.4893 | 0.0624 | 0.4465 | 0.5310 | 0.0845 |
| PMM2  | 0.4936 | 0.4940 | 0.0486 | 0.4606 | 0.5265 | 0.0659 |
| True  | 0.5000 | -      | -      | -      | -      | -      |

**Висновки:**
- PMM2 має **меншу дисперсію** (Std: 0.0486 vs 0.0624)
- PMM2 має **менше зміщення** (Mean: 0.4936 vs 0.4888)
- **Міжквартильний розмах (IQR)** на 22% менший для PMM2

**3.4.2. Тести нормальності**

Kolmogorov-Smirnov тест застосовано до розподілів стандартизованих оцінок:

$$Z = \frac{\hat{\phi}_1 - \phi_0}{\widehat{SE}(\hat{\phi}_1)}$$

**Результати:**
- CSS: KS-statistic = 0.018, p-value = 0.624 ✓
- PMM2: KS-statistic = 0.021, p-value = 0.438 ✓

**Висновок:** Обидва методи демонструють асимптотичну нормальність (не відхиляємо гіпотезу нормальності на рівні 5%).

### 3.5. Обчислювальна ефективність

**3.5.1. Час виконання**

Середній час виконання одної оцінки (Intel i7, Python 3.9, N=500):

| Метод | Час (мс) | Відносно CSS |
|-------|----------|--------------|
| CSS   | 2.3      | 1.0×         |
| PMM2  | 3.8      | 1.65×        |

**Інтерпретація:**
- PMM2 вимагає додаткових **1.5 мс** на симуляцію
- Збільшення часу на **65%** є прийнятним для практичних застосувань
- Час зростає переважно через ітеративну процедуру Ньютона-Рафсона

**3.5.2. Збіжність PMM2 алгоритму**

Аналіз збіжності для Gamma інновацій (N=500, 2000 симуляцій):

| Ітерацій | Частота | Кумулятивна |
|----------|---------|-------------|
| 1        | 2.1%    | 2.1%        |
| 2        | 15.3%   | 17.4%       |
| 3        | 32.8%   | 50.2%       |
| 4        | 28.1%   | 78.3%       |
| 5        | 15.2%   | 93.5%       |
| 6+       | 6.3%    | 99.8%       |
| Не збіглось | 0.2% | 100.0%      |

**Середня кількість ітерацій:** 3.8  
**Медіана:** 4 ітерації

**Висновок:** Алгоритм збігається швидко і надійно (99.8% успішна збіжність).

### 3.6. Діагностика залишків

**3.6.1. Тест на білий шум**

Ljung-Box Q-тест застосовано до залишків обох методів для перевірки автокореляції.

**Результати (усереднені по 2000 симуляціях, Gamma, N=500):**

| Метод | Q(10) | p-value | Автокор. |
|-------|-------|---------|----------|
| CSS   | 9.32  | 0.502   | Ні ✓     |
| PMM2  | 9.18  | 0.516   | Ні ✓     |

**Висновок:** Залишки обох методів не демонструють значущої автокореляції.

**3.6.2. Моменти залишків**

Порівняння емпіричних моментів залишків з теоретичними:

| Момент | Теоретичний | CSS   | PMM2  |
|--------|-------------|-------|-------|
| $\mu$  | 0.00        | 0.001 | 0.001 |
| $\sigma^2$ | 1.00    | 0.998 | 0.997 |
| $\gamma_3$ | 1.41    | 1.35  | 1.34  |
| $\gamma_4$ | 3.00    | 2.82  | 2.79  |

**Висновок:** Залишки обох методів відповідають очікуваним характеристикам інновацій.

---

