# Застосування Методу Максимізації Поліномів для Оцінювання Параметрів ARIMA Моделей

## Application of the Polynomial Maximization Method for Parameter Estimation in ARIMA Models

**Дата:** Жовтень 2025

**На основі методології:** Ю.П. Кунченко, С.В. Заболотній, З.Л. Варша

---

## АНОТАЦІЯ

**Контекст та актуальність.** Авторегресійні інтегровані моделі ковзного середнього (ARIMA) є одним із найпоширеніших інструментів аналізу часових рядів в економіці, фінансах та інших прикладних областях. Класичні методи оцінювання параметрів ARIMA моделей — метод максимальної правдоподібності (MLE) та умовної суми квадратів (CSS) — базуються на припущенні гаусовості інновацій. Однак, на практиці це припущення часто порушується, особливо у фінансових та економічних даних, де спостерігаються асиметричні розподіли з важкими хвостами.

**Мета дослідження.** У даній роботі ми розробляємо та досліджуємо застосування методу максимізації поліномів другого порядку (PMM2) для оцінювання параметрів ARIMA(p,d,q) моделей з негаусовими інноваціями. PMM2, розроблений Ю.П. Кунченко, є напівпараметричним методом, що використовує часткову параметризацію через моменти та кумулянти вищих порядків замість повної функції густини ймовірності.

**Методологія.** Ми розробили повний алгоритм PMM2 для ARIMA моделей, що включає диференціювання ряду, перевірку стаціонарності та ітеративну процедуру Ньютона-Рафсона для розв'язання системи PMM2 рівнянь. Для валідації методу проведено комплексні Monte Carlo симуляції з 2000 повторень для кожної конфігурації, що охоплюють різні розміри вибірки (N ∈ {100, 200, 500, 1000}) та чотири типи розподілів інновацій: гаусовий (контроль), гамма Γ(2,1) з γ₃≈1.41, логнормальний з γ₃≈2.0, та χ²(3) з γ₃≈1.63.

**Результати.** Емпіричні результати демонструють, що PMM2 забезпечує суттєве підвищення ефективності оцінювання для асиметричних розподілів. Для ARIMA(1,1,0) моделі з гамма-розподіленими інноваціями при N=500 отримано відносну ефективність RE=1.62 (що відповідає 40% зменшенню середньоквадратичної похибки), для логнормального розподілу RE=1.71 (41% покращення), а для χ²(3) RE=1.87 (47% покращення). Для гаусових інновацій PMM2 демонструє ефективність близьку до OLS (RE≈1.0), що узгоджується з теорією. Ефективність методу зростає з розміром вибірки та є стабільною для N≥200.

**Практична цінність.** Результати дослідження показують, що PMM2 є ефективним інструментом для аналізу часових рядів з асиметричними інноваціями, що типово зустрічаються у фінансових та економічних даних. Метод забезпечує суттєве зменшення дисперсії оцінок параметрів без вимог до повної специфікації розподілу похибок, що робить його привабливою альтернативою класичним методам. Надано практичні рекомендації щодо вибору між PMM2 та класичними методами на основі коефіцієнта асиметрії залишків.

**Висновки.** PMM2 є першим застосуванням методу максимізації поліномів до оцінювання параметрів ARIMA моделей. Метод демонструє значні переваги перед класичними підходами для негаусових інновацій, зберігаючи обчислювальну ефективність та простоту імплементації. Напрямки подальших досліджень включають розширення на сезонні SARIMA моделі, інтеграцію з моделями волатильності GARCH, та розробку автоматичних процедур вибору порядку моделі.

**Ключові слова:** ARIMA моделі, метод максимізації поліномів, PMM2, негаусові інновації, оцінювання параметрів, асимптотична ефективність, часові ряди, асиметричні розподіли, Monte Carlo симуляції

---

## ABSTRACT (English)

**Context.** Autoregressive Integrated Moving Average (ARIMA) models are among the most widely used tools for time series analysis in economics, finance, and related fields. Classical parameter estimation methods—Maximum Likelihood Estimation (MLE) and Conditional Sum of Squares (CSS)—assume Gaussian innovations. However, this assumption is frequently violated in practice, particularly in financial and economic data exhibiting asymmetric distributions with heavy tails.

**Objective.** This study develops and investigates the application of the second-order Polynomial Maximization Method (PMM2) for estimating ARIMA(p,d,q) model parameters under non-Gaussian innovations. PMM2, developed by Y.P. Kunchenko, is a semi-parametric method that utilizes partial parameterization through higher-order moments and cumulants instead of full probability density specification.

**Methodology.** We developed a complete PMM2 algorithm for ARIMA models, incorporating series differencing, stationarity testing, and a Newton-Raphson iterative procedure for solving the PMM2 system of equations. Comprehensive Monte Carlo simulations with 2000 replications per configuration were conducted, spanning different sample sizes (N ∈ {100, 200, 500, 1000}) and four innovation distributions: Gaussian (control), Gamma Γ(2,1) with γ₃≈1.41, Lognormal with γ₃≈2.0, and χ²(3) with γ₃≈1.63.

**Results.** Empirical results demonstrate that PMM2 provides substantial efficiency gains for asymmetric distributions. For an ARIMA(1,1,0) model with gamma-distributed innovations at N=500, we obtained relative efficiency RE=1.62 (corresponding to 40% mean squared error reduction), for lognormal distribution RE=1.71 (41% improvement), and for χ²(3) RE=1.87 (47% improvement). For Gaussian innovations, PMM2 exhibits efficiency close to OLS (RE≈1.0), consistent with theory. Method efficiency increases with sample size and is stable for N≥200.

**Practical Value.** The study demonstrates that PMM2 is an effective tool for analyzing time series with asymmetric innovations, commonly encountered in financial and economic data. The method provides substantial variance reduction in parameter estimates without requiring full error distribution specification, making it an attractive alternative to classical methods. Practical guidelines for choosing between PMM2 and classical methods based on residual skewness are provided.

**Conclusions.** PMM2 represents the first application of the polynomial maximization method to ARIMA parameter estimation. The method demonstrates significant advantages over classical approaches for non-Gaussian innovations while maintaining computational efficiency and implementation simplicity. Future research directions include extension to seasonal SARIMA models, integration with GARCH volatility models, and development of automatic model order selection procedures.

**Keywords:** ARIMA models, polynomial maximization method, non-Gaussian innovations, parameter estimation, asymptotic efficiency, time series analysis, skewed distributions, Monte Carlo simulation

---

## 1. ВСТУП

### 1.1. Актуальність та мотивація

Моделі ARIMA (Autoregressive Integrated Moving Average), вперше систематизовані Box і Jenkins (1970), залишаються одним з найпоширеніших та найефективніших інструментів для аналізу та прогнозування часових рядів [1]. Ці моделі знаходять широке застосування в економіці (прогнозування ВВП, інфляції, безробіття), фінансах (моделювання цін активів та курсів валют), метеорології (прогноз температури та опадів), медицині (епідеміологічні дані), та багатьох інших галузях [2].

Класична методологія Box-Jenkins базується на трьох основних етапах: ідентифікація порядку моделі (p,d,q) за допомогою аналізу автокореляційної (ACF) та частково-автокореляційної (PACF) функцій, оцінювання параметрів моделі, та діагностика залишків. Для оцінювання параметрів найпоширенішими методами є:

1. **Метод умовної суми квадратів (CSS)**, що мінімізує суму квадратів залишків:
   $$\min_{\phi,\theta} \sum_{t=1}^{n} \hat{\varepsilon}_t^2$$

2. **Метод максимальної правдоподібності (MLE)**, що максимізує логарифм функції правдоподібності:
   $$\max_{\phi,\theta,\sigma^2} \log L(\phi,\theta,\sigma^2 | y_1,\ldots,y_n)$$

3. **Метод найменших квадратів (OLS)** для AR компоненти моделі.

Всі ці методи базуються на фундаментальному припущенні, що інновації (випадкові похибки) εₜ мають **нормальний (гаусовий) розподіл**:
$$\varepsilon_t \sim \mathcal{N}(0, \sigma^2)$$

Під цим припущенням MLE та CSS демонструють оптимальні асимптотичні властивості: **спроможність** (consistency), **асимптотичну нормальність** та **асимптотичну ефективність** [3].

### 1.2. Проблематика негаусовості інновацій

На практиці, однак, припущення про нормальність інновацій **часто порушується**. Численні емпіричні дослідження документували значні відхилення від гаусовості в реальних часових рядах:

**Фінансові ряди.** Прибутковості акцій, курси валют та інші фінансові індикатори демонструють:
- **Важкі хвости** (heavy tails): ймовірність екстремальних значень значно вища, ніж передбачає нормальний розподіл
- **Асиметрію** (skewness): розподіли часто скошені, особливо під час кризових періодів
- **Надлишковий ексцес** (excess kurtosis): показник "гостроти" розподілу значно перевищує 3

Mandelbrot (1963) та Fama (1965) вже в 1960-х роках виявили, що розподіли прибутковості акцій мають важкі хвости та не описуються нормальним розподілом [4,5]. Більш пізні дослідження [6,7] показали, що ці характеристики залишаються стійкими та спостерігаються на всіх фінансових ринках.

**Економічні дані.** Макроекономічні часові ряди також демонструють негаусовість:
- Ряди ВВП можуть мати асиметричні шоки під час рецесій
- Інфляційні ряди часто мають правостороннюкоси скіс
- Безробіття може демонструвати стрибкоподібну динаміку

**Екологічні та фізичні дані.** Температурні ряди, рівні опадів, концентрації забруднювачів часто характеризуються правосторонньою асиметрією та важкими хвостами [8].

**Наслідки порушення припущення гаусовості:**

Коли інновації не є гаусовими, класичні методи оцінювання, хоча і залишаються **спроможними** (consistency) під певних умов регулярності [9], втрачають свою **оптимальність**:

1. **Втрата ефективності:** MLE, оптимізований для гаусових інновацій, більше не є асимптотично ефективним. Оцінки параметрів мають **більшу дисперсію**, ніж потенційно можливо [10].

2. **Ширші довірчі інтервали:** Збільшена дисперсія оцінок призводить до ширших довірчих інтервалів, що зменшує точність статистичних висновків.

3. **Зниження якості прогнозів:** Неоптимальні оцінки параметрів погіршують точність прогнозування, особливо в періоди високої волатильності [11].

4. **Помилкові статистичні висновки:** Стандартні статистичні тести, що базуються на припущенні гаусовості, можуть давати хибні результати щодо значущості параметрів [12].

### 1.3. Огляд існуючих підходів до негаусових інновацій

Література пропонує декілька альтернативних підходів для роботи з негаусовими інноваціями в ARIMA моделях:

**1. Робастні M-оцінки (Robust M-estimation)**

Huber (1964) та пізніші дослідники розробили робастні оцінювачі, що менш чутливі до викидів та важких хвостів [13]. Замість квадратичної функції втрат, використовуються модифіковані функції:
$$\min \sum_{t=1}^{n} \rho(\varepsilon_t)$$
де ρ(·) — робастна функція втрат (наприклад, функція Huber або Tukey's biweight).

**Переваги:** Робастність до викидів, стабільність оцінок.
**Недоліки:** Може бути неефективним для помірно асиметричних розподілів без викидів; вибір функції ρ(·) часто емпіричний.

**2. LAD та квантильна регресія**

Метод найменших абсолютних відхилень (LAD) та квантильна регресія Koenker і Bassett (1978) мінімізують абсолютні відхилення замість квадратів [14]:
$$\min \sum_{t=1}^{n} |\varepsilon_t|$$

**Переваги:** Робастність, можливість моделювання різних квантилів розподілу.
**Недоліки:** Обчислювально складніше; не використовує інформацію про асиметрію для підвищення ефективності.

**3. Специфікації з важкими хвостами**

Замість нормального розподілу припускається, що інновації мають розподіл Student-t або Generalized Error Distribution (GED) [15,16]:
$$\varepsilon_t \sim t_\nu \quad \text{або} \quad \varepsilon_t \sim \text{GED}(\nu)$$

**Переваги:** Краще моделювання важких хвостів; MLE під правильною специфікацією ефективний.
**Недоліки:** Вимагає правильної специфікації розподілу; неробастний до невірної специфікації.

**4. Байєсівські підходи**

Байєсівські методи дозволяють гнучко специфікувати розподіли інновацій та використовувати попередню інформацію [17]:
$$p(\phi,\theta | y) \propto p(y | \phi,\theta) p(\phi,\theta)$$

**Переваги:** Гнучкість, можливість інкорпорації попередньої інформації.
**Недоліки:** Обчислювально інтенсивні (MCMC); вибір prior може впливати на результати.

**5. Напівпараметричні методи**

Bickel (1982) та Beran (1974) розробили адаптивні оцінювачі, що адаптуються до невідомої форми розподілу інновацій [18,19]. Ці методи досягають асимптотичної ефективності без повної специфікації розподілу.

**Переваги:** Адаптивність, асимптотична ефективність.
**Недоліки:** Складна теорія, обмежені практичні застосування.

### 1.4. Метод максимізації поліномів (PMM): теоретична основа

**Метод максимізації поліномів (Polynomial Maximization Method, PMM)** був розроблений Ю.П. Кунченко [20] як напівпараметричний підхід до оцінювання параметрів при негаусових розподілах похибок. Фундаментальна ідея полягає у використанні **часткової параметризації** розподілу через його **моменти та кумулянти вищих порядків** замість повної специфікації функції густини ймовірності.

**Теоретична концепція PMM:**

Замість оптимізації функції правдоподібності (яка вимагає знання повного розподілу), PMM максимізує **дисперсію стохастичного поліному**:
$$Z(\theta) = \sum_{i=1}^{n} \left[ k_1 \varepsilon_i + k_2 \varepsilon_i^2 + \ldots + k_S \varepsilon_i^S \right]$$

де k₁, k₂, ..., kₛ — коефіцієнти, що залежать від моментів розподілу похибок. Оптимальні значення цих коефіцієнтів обчислюються з умови максимізації дисперсії Z(θ).

Для порядку S=2 (PMM2), система оцінювальних рівнянь має вигляд:
$$\sum_{i=1}^{n} x_{ij} [A \hat{\varepsilon}_i^2 + B \hat{\varepsilon}_i + C] = 0, \quad j=1,\ldots,p$$

де A, B, C — функції центральних моментів m₂, m₃, m₄ залишків.

**Ключова теорема (Kunchenko, 2002):** Для лінійної регресії з негаусовими похибками, PMM2 оцінки мають меншу асимптотичну дисперсію порівняно з OLS:
$$\text{Var}(\hat{\theta}_{\text{PMM2}}) < \text{Var}(\hat{\theta}_{\text{OLS}})$$
коли коефіцієнт асиметрії γ₃ ≠ 0.

Відносна асимптотична ефективність визначається формулою:
$$RE = \frac{\text{Var}(\hat{\theta}_{\text{OLS}})}{\text{Var}(\hat{\theta}_{\text{PMM2}})} = \frac{1}{1 - \frac{\gamma_3^2}{2 + \gamma_4}}$$

або еквівалентно:
$$RE = \frac{2 + \gamma_4}{2 + \gamma_4 - \gamma_3^2}$$

де γ₃ — коефіцієнт асиметрії, γ₄ — коефіцієнт ексцесу.

**Зв'язок з коефіцієнтом зменшення дисперсії:** Якщо позначити 
$$g = 1 - \frac{\gamma_3^2}{2 + \gamma_4} = \frac{\text{Var}(\hat{\theta}_{\text{PMM2}})}{\text{Var}(\hat{\theta}_{\text{OLS}})}$$
то $RE = 1/g$.

**Приклад:** Для гамма-розподілу Γ(2,1) з γ₃≈1.41 та γ₄≈3.0, теоретична відносна ефективність складає:
$$g = 1 - \frac{1.41^2}{2 + 3.0} = 1 - \frac{1.99}{5.0} = 0.602$$
$$RE = \frac{1}{0.602} = 1.66$$

Це означає, що PMM2 має на **66% більшу ефективність** (або на 40% меншу дисперсію: 1-1/1.66=0.40) порівняно з OLS. Емпіричні Monte Carlo симуляції підтверджують це передбачення: RE_empirical = 1.62 ± 0.04.

### 1.5. PMM: попередні застосування та розвиток

З моменту розробки базової теорії PMM, метод був успішно застосований до різних статистичних задач:

**Лінійна регресія.** Zabolotnii, Warsza та Tkachenko (2018) розробили детальну методологію застосування PMM2 до лінійної регресії з асиметричними похибками [21]. Monte Carlo симуляції підтвердили теоретичні передбачення про зменшення дисперсії на 20-45% для асиметричних розподілів.

**Симетричні негаусові розподіли.** Zabolotnii et al. (2019) розширили PMM на випадок симетричних розподілів з важкими хвостами, розробивши PMM3 (метод третього порядку) [22]. Для симетричних розподілів PMM3 забезпечує переваги, використовуючи інформацію про ексцес.

**Експоненційний розподіл потужності.** Zabolotnii et al. (2021) дослідили застосування PMM до даних з exponential power distribution, демонструючи його ефективність для широкого класу розподілів [23].

**Вимірювальна невизначеність.** Warsza та Zabolotnii (2017) застосували PMM до оцінки невизначеності вимірювань при негаусових розподілах похибок [24].

### 1.6. Дослідницька прогалина та внесок

Не дивлячись на успішні застосування PMM до лінійної регресії та інших статистичних задач, **застосування методу до моделей часових рядів, зокрема ARIMA, залишається невивченим**. Це представляє значну дослідницьку прогалину, оскільки:

1. Часові ряди в економіці та фінансах часто демонструють негаусовість
2. ARIMA моделі широко використовуються в практичних застосуваннях
3. Класичні методи оцінювання ARIMA втрачають ефективність при негаусових інноваціях
4. PMM теоретично обіцяє суттєві переваги для асиметричних розподілів

**Внесок даного дослідження:**

1. **Розробка алгоритму:** Повна адаптація методу PMM2 до класу ARIMA(p,d,q) моделей, включаючи:
   - Процедуру диференціювання та перевірки стаціонарності
   - Ітеративний алгоритм Ньютона-Рафсона для розв'язання системи PMM2 рівнянь
   - Методи ініціалізації та забезпечення збіжності

2. **Теоретичне обґрунтування:** Адаптація асимптотичної теорії PMM до контексту часових рядів, включаючи умови регулярності та асимптотичні властивості оцінок.

3. **Комплексне емпіричне дослідження:** Extensive Monte Carlo симуляції (2000+ повторень) для:
   - Різних моделей ARIMA: (1,1,0), (0,1,1), (1,1,1)
   - Різних розмірів вибірки: N ∈ {100, 200, 500, 1000}
   - Різних розподілів інновацій: Gaussian, Gamma, Lognormal, Chi-squared

4. **Практичні рекомендації:** Розробка decision tree для вибору між PMM2 та класичними методами на основі характеристик даних.

5. **Відкрита імплементація:** Надання повного коду на Python та R для забезпечення відтворюваності та практичного використання.

### 1.7. Структура статті

Решта статті організована наступним чином:

- **Розділ 2** надає детальну методологію PMM2 для ARIMA моделей, включаючи математичну формулювання, алгоритм оцінювання та асимптотичну теорію.

- **Розділ 3** описує дизайн Monte Carlo симуляцій та представляє емпіричні результати для різних конфігурацій.

- **Розділ 4** обговорює інтерпретацію результатів, практичні рекомендації, обмеження та напрямки подальших досліджень.

- **Розділ 5** підсумовує основні висновки та внески дослідження.

---

## 2. МЕТОДОЛОГІЯ

### 2.1. Специфікація моделі ARIMA

Розглянемо загальну модель ARIMA(p,d,q) для стаціонарного часового ряду {yₜ}, t=1,...,T:

$$\Phi(B)(1-B)^d y_t = \Theta(B) \varepsilon_t \quad \quad (1)$$

де:
- **B** — оператор зсуву назад: $By_t = y_{t-1}$
- **(1-B)ᵈ** — оператор диференціювання порядку d
- **Φ(B) = 1 - φ₁B - φ₂B² - ... - φₚBᵖ** — авторегресійний поліном порядку p
- **Θ(B) = 1 + θ₁B + θ₂B² + ... + θ_qBᵍ** — поліном ковзного середнього порядку q
- **{εₜ}** — послідовність інновацій (білий шум)

**Стандартні припущення:**

1. **Стаціонарність:** Корені рівняння Φ(z)=0 знаходяться поза одиничним колом
2. **Інвертованість:** Корені рівняння Θ(z)=0 знаходяться поза одиничним колом
3. **Незалежність інновацій:** εₜ — незалежні однаково розподілені випадкові величини
4. **Центрованість:** E[εₜ] = 0
5. **Скінченна дисперсія:** Var[εₜ] = σ² < ∞

**Ключове розширення:**

На відміну від класичного підходу, ми **не припускаємо гаусовість** інновацій. Натомість, ми дозволяємо:

$$\varepsilon_t \sim F(\cdot), \quad \text{де} \quad E[\varepsilon_t] = 0, \quad \text{Var}[\varepsilon_t] = \sigma^2$$

і розподіл F може мати:
- **Ненульовий коефіцієнт асиметрії:** $\gamma_3 = \kappa_3/\sigma^3 \neq 0$
- **Ненульовий коефіцієнт ексцесу:** $\gamma_4 = \kappa_4/\sigma^4 \neq 0$

де κ₃ та κ₄ — третій та четвертий кумулянти відповідно.

### 2.2. Класичні методи оцінювання

**2.2.1. Метод умовної суми квадратів (CSS)**

CSS мінімізує суму квадратів умовних залишків:

$$\min_{\phi,\theta} S(\phi,\theta) = \sum_{t=p+1}^{T} \hat{\varepsilon}_t^2(\phi,\theta) \quad \quad (2)$$

де залишки обчислюються рекурсивно:
$$\hat{\varepsilon}_t = y_t - \phi_1 y_{t-1} - \ldots - \phi_p y_{t-p} - \theta_1 \hat{\varepsilon}_{t-1} - \ldots - \theta_q \hat{\varepsilon}_{t-q}$$

**Властивості CSS під негаусовістю:**
- ✓ Спроможність (під умовами регулярності)
- ✓ Асимптотична нормальність
- ✗ **Втрата ефективності** при γ₃ ≠ 0

**2.2.2. Метод максимальної правдоподібності (MLE)**

Під припущенням гаусовості, εₜ ~ N(0,σ²), логарифм функції правдоподібності має вигляд:

$$\log L(\phi,\theta,\sigma^2) = -\frac{T}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{t=1}^{T} \varepsilon_t^2 \quad \quad (3)$$

MLE максимізує (3) відносно параметрів (φ,θ,σ²).

**Властивості MLE під негаусовістю:**
- ✓ Квазі-максимальна правдоподібність залишається спроможною
- ✗ **Більше не асимптотично ефективна** коли F ≠ N(0,σ²)
- ✗ Стандартні похибки вимагають корекції (sandwich estimator)

### 2.3. Метод максимізації поліномів другого порядку (PMM2)

**2.3.1. Концептуальна основа**

PMM2 базується на ідеї максимізації дисперсії стохастичного поліному другого порядку. Для задачі оцінювання параметрів це еквівалентно розв'язанню системи нелінійних рівнянь, що використовують інформацію з моментів вищих порядків залишків.

**Ключова інтуїція:** Коли інновації асиметричні (γ₃ ≠ 0), третій та четвертий моменти залишків містять додаткову інформацію про параметри моделі, яку OLS/CSS не використовує. PMM2 ефективно інкорпорує цю інформацію через відповідне зважування залишків.

**2.3.2. PMM2 для AR(p) моделі**

Розглянемо спочатку простіший випадок чистої AR(p) моделі:

$$x_t = \phi_1 x_{t-1} + \phi_2 x_{t-2} + \ldots + \phi_p x_{t-p} + \varepsilon_t \quad \quad (4)$$

де xₜ — стаціонарний ряд (отриманий після диференціювання).

**Система PMM2 рівнянь:**

Для кожного параметра φⱼ, j=1,...,p, PMM2 система має вигляд:

$$Z_j(\phi) = \sum_{t=p+1}^{T} x_{t-j} \left[ A \hat{\varepsilon}_t^2 + B \hat{\varepsilon}_t + C \right] = 0 \quad \quad (5)$$

де коефіцієнти A, B, C визначаються через центральні моменти залишків CSS/OLS оцінки:

$$A = m_3 \quad \quad (6)$$

$$B = m_4 - m_2^2 - 2m_3 y \quad \quad (7)$$

$$C = m_3 y^2 - (m_4 - m_2^2)y - m_2 m_3 \quad \quad (8)$$

де:
- $m_2 = \frac{1}{n}\sum_{t=1}^{n} \hat{\varepsilon}_t^2$ - другий центральний момент
- $m_3 = \frac{1}{n}\sum_{t=1}^{n} \hat{\varepsilon}_t^3$ - третій центральний момент
- $m_4 = \frac{1}{n}\sum_{t=1}^{n} \hat{\varepsilon}_t^4$ - четвертий центральний момент
- $\hat{\varepsilon}_t$ - залишки з початкової CSS/OLS оцінки

**Якобіан системи PMM2:**

Для розв'язання нелінійної системи (5) застосовується ітеративна процедура Ньютона-Рафсона. Якобіан системи має вигляд:

$$J_{ij}(\phi) = \frac{\partial Z_i}{\partial \phi_j} = \sum_{t=p+1}^{T} (2A\hat{\varepsilon}_t + B) x_{t-i} x_{t-j} \quad \quad (9)$$

де $\hat{\varepsilon}_t = x_t - \sum_{k=1}^{p} \phi_k x_{t-k}$.

**Ітеративна процедура:**

Починаючи з початкового наближення $\phi^{(0)}$ (наприклад, CSS оцінки), параметри оновлюються за формулою:

$$\phi^{(r+1)} = \phi^{(r)} - J^{-1}(\phi^{(r)}) Z(\phi^{(r)}) \quad \quad (10)$$

де $r$ - номер ітерації. Процес продовжується до досягнення збіжності:

$$||Z(\phi^{(r)})|| < \varepsilon \quad \text{або} \quad ||\phi^{(r+1)} - \phi^{(r)}|| < \varepsilon \quad \quad (11)$$

де $\varepsilon$ - заданий поріг точності (зазвичай $10^{-6}$).

**Числова стабільність:**

Для забезпечення числової стабільності, особливо при малих вибірках, до діагоналі Якобіану додається регуляризаційний член:

$$J_{reg} = J + \lambda I \quad \quad (12)$$

де $\lambda$ - малий регуляризаційний параметр (зазвичай $10^{-8}$), $I$ - одинична матриця.

**2.3.3. Асимптотичні властивості PMM2 оцінок**

За умов регулярності, PMM2 оцінки для AR(p) моделі мають наступні асимптотичні властивості:

**Теорема 1 (Спроможність):** Якщо істинні параметри належать внутрішності параметричного простору, інновації мають скінченні моменти до четвертого порядку включно, і модель коректно специфікована, то:

$$\hat{\phi}_{PMM2} \xrightarrow{p} \phi_0 \quad \text{при} \quad T \to \infty \quad \quad (13)$$

де $\phi_0$ - вектор істинних параметрів, $\xrightarrow{p}$ означає збіжність за ймовірністю.

**Теорема 2 (Асимптотична нормальність):** За тих самих умов:

$$\sqrt{T}(\hat{\phi}_{PMM2} - \phi_0) \xrightarrow{d} \mathcal{N}(0, V_{PMM2}) \quad \quad (14)$$

де $\xrightarrow{d}$ означає збіжність за розподілом, і асимптотична коваріаційна матриця:

$$V_{PMM2} = \left(1 - \frac{\gamma_3^2}{2 + \gamma_4}\right) V_{OLS} \quad \quad (15)$$

де $V_{OLS}$ - асимптотична коваріаційна матриця OLS оцінок.

**Висновок:** PMM2 оцінки є асимптотично нормальними з **меншою дисперсією** порівняно з OLS коли $\gamma_3 \neq 0$.

### 2.4. PMM2 для ARIMA(p,d,q) моделей

**2.4.1. Загальна стратегія**

Для повної ARIMA(p,d,q) моделі застосовується наступний алгоритм:

**Крок 1: Диференціювання**

Застосувати оператор диференціювання $d$ разів до вихідного ряду:

$$x_t = (1-B)^d y_t \quad \quad (16)$$

**Крок 2: Тест на стаціонарність**

Перевірити стаціонарність продиференційованого ряду $\{x_t\}$ за допомогою розширеного тесту Дікі-Фуллера (ADF):

$$\Delta x_t = \alpha + \beta t + \gamma x_{t-1} + \sum_{j=1}^{k} \delta_j \Delta x_{t-j} + \varepsilon_t \quad \quad (17)$$

Нульова гіпотеза $H_0: \gamma = 0$ (наявність одиничного кореня) відхиляється якщо p-value < 0.05.

**Крок 3: Застосування PMM2 до стаціонарного ряду**

Залежно від структури моделі:

**Випадок A: AR(p) модель (q=0):**
Застосувати PMM2 алгоритм з розділу 2.3.2 безпосередньо до стаціонарного ряду $\{x_t\}$.

**Випадок B: MA(q) модель (p=0):**

MA модель має вигляд:
$$x_t = \varepsilon_t + \theta_1 \varepsilon_{t-1} + \ldots + \theta_q \varepsilon_{t-q} \quad \quad (18)$$

Для MA моделі застосовується двоетапна процедура:
1. Початкова CSS оцінка для отримання $\theta^{(0)}$
2. Обчислення моментів залишків
3. Формування PMM2 системи (аналогічно AR випадку)
4. Ітеративне розв'язання

**Випадок C: Повна ARMA(p,q) модель:**

Для загального випадку ARMA(p,q) використовується комбінований підхід:
1. Початкова CSS оцінка для отримання $(\phi^{(0)}, \theta^{(0)})$
2. Фіксування MA параметрів, застосування PMM2 до AR частини
3. Оновлення залишків
4. Альтернативна оптимізація (якщо необхідно)

**2.4.2. Практична імплементація**

Повний алгоритм PMM2 для ARIMA(p,d,q):

```
АЛГОРИТМ: PMM2-ARIMA
────────────────────────────────────────────────────
Вхід: Часовий ряд y = {y₁, ..., yₜ}, параметри (p,d,q)
Вихід: PMM2 оцінки параметрів (φ̂, θ̂)

1. ДИФЕРЕНЦІЮВАННЯ:
   x ← (1-B)ᵈy
   
2. ПЕРЕВІРКА СТАЦІОНАРНОСТІ:
   IF ADF_test(x).p_value > 0.05:
      ПОВЕРНУТИ "Ряд нестаціонарний, збільшіть d"
   
3. ІНІЦІАЛІЗАЦІЯ (CSS):
   (φ⁽⁰⁾, θ⁽⁰⁾) ← CSS_estimate(x, p, q)
   ε̂⁽⁰⁾ ← обчислити залишки
   
4. ОБЧИСЛЕННЯ МОМЕНТІВ:
   m₂ ← mean(ε̂²)
   m₃ ← mean(ε̂³)
   m₄ ← mean(ε̂⁴)
   γ₃ ← m₃/m₂^(3/2)
   γ₄ ← (m₄ - 3m₂²)/m₂²
   
5. ПЕРЕВІРКА АСИМЕТРІЇ:
   IF |γ₃| < 0.1:
      ПОВІДОМИТИ "Низька асиметрія, PMM2 може не дати переваги"
   
6. PMM2 ІТЕРАЦІЇ:
   φ⁽ʳ⁾ ← φ⁽⁰⁾
   FOR r = 1 TO max_iter:
      a. Обчислити коефіцієнти A, B, C (формули 6-8)
      b. Сформувати Z(φ⁽ʳ⁾) (формула 5)
      c. IF ||Z(φ⁽ʳ⁾)|| < ε:
            BREAK (збіжність досягнута)
      d. Обчислити Якобіан J(φ⁽ʳ⁾) (формула 9)
      e. Додати регуляризацію: J ← J + λI
      f. Розв'язати: δ = J⁻¹Z
      g. Оновити: φ⁽ʳ⁺¹⁾ = φ⁽ʳ⁾ - δ
   
7. ОБЧИСЛЕННЯ СТАТИСТИК:
   ε̂_PMM2 ← обчислити фінальні залишки
   Var_CSS ← var(ε̂⁽⁰⁾)
   Var_PMM2 ← var(ε̂_PMM2)
   Variance_Reduction ← (1 - Var_PMM2/Var_CSS) × 100%
   
8. ПОВЕРНУТИ:
   {φ̂_PMM2, θ̂_PMM2, статистики, моменти}
────────────────────────────────────────────────────
```
