\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[ukrainian,english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=2.5cm}

% Визначення theorem environments
\newtheorem{theorem}{Теорема}[section]
\newtheorem{definition}[theorem]{Визначення}
\newtheorem{lemma}[theorem]{Лема}
\newtheorem{corollary}[theorem]{Наслідок}
\newtheorem{proposition}[theorem]{Твердження}

% Налаштування hyperref
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    citecolor=blue,
}

\title{Застосування Методу Максимізації Поліномів для Оцінювання Параметрів ARIMA Моделей з Негаусовими Інноваціями}

\author{Сергій Заболотній\thanks{Industrial Research Institute for Automation and Measurements PIAP, Warsaw, Poland. Email: zabolotniua@gmail.com}}

\date{\today}

\begin{document}

\maketitle

% ============================================
% ABSTRACT - UKRAINIAN
% ============================================
\begin{abstract}
\selectlanguage{ukrainian}

\textbf{Контекст та актуальність.} Авторегресійні інтегровані моделі ковзного середнього (ARIMA) є одним із найпоширеніших інструментів аналізу часових рядів в економіці, фінансах та інших прикладних областях. Класичні методи оцінювання параметрів ARIMA моделей --- метод максимальної правдоподібності (MLE), метод умовної суми квадратів (CSS) та звичайний метод найменших квадратів (OLS) --- базуються на фундаментальному припущенні гаусовості інновацій. На практиці, це припущення часто порушується, особливо у фінансових та економічних даних, де спостерігаються асиметричні розподіли з важкими хвостами.

\textbf{Мета дослідження.} У даній роботі ми розробляємо та досліджуємо застосування методу максимізації поліномів другого порядку (PMM2) для оцінювання параметрів ARIMA(p,d,q) моделей з негаусовими інноваціями. PMM2, розроблений Ю.П. Кунченко, є напівпараметричним методом, що використовує часткову параметризацію через моменти та кумулянти вищих порядків замість повної функції густини ймовірності.

\textbf{Методологія.} Ми розробили повний алгоритм PMM2 для ARIMA моделей, що включає диференціювання ряду, перевірку стаціонарності та ітеративну процедуру Ньютона-Рафсона для розв'язання системи PMM2 рівнянь. Для валідації методу проведено комплексні Monte Carlo симуляції з 2000 повторень для кожної конфігурації, що охоплюють різні розміри вибірки (N~$\in$~\{100, 200, 500, 1000\}) та чотири типи розподілів інновацій: гаусовий (контроль), гамма $\Gamma(2,1)$ з $\gamma_3 \approx 1.41$, логнормальний з $\gamma_3 \approx 2.0$, та $\chi^2(3)$ з $\gamma_3 \approx 1.63$.

\textbf{Результати.} Емпіричні результати демонструють, що PMM2 забезпечує суттєве підвищення ефективності оцінювання для асиметричних розподілів. Для ARIMA(1,1,0) моделі з гамма-розподіленими інноваціями при N=500 отримано відносну ефективність RE=1.62 (що відповідає 40\% зменшенню середньоквадратичної похибки), для логнормального розподілу RE=1.71 (41\% покращення), а для $\chi^2(3)$ RE=1.87 (47\% покращення). Для гаусових інновацій PMM2 демонструє ефективність близьку до OLS (RE~$\approx$~1.0), що узгоджується з теорією. Ефективність методу зростає з розміром вибірки та є стабільною для N~$\geq$~200.

\textbf{Практична цінність.} Результати дослідження показують, що PMM2 є ефективним інструментом для аналізу часових рядів з асиметричними інноваціями, що типово зустрічаються у фінансових та економічних даних. Метод забезпечує суттєве зменшення дисперсії оцінок параметрів без вимог до повної специфікації розподілу похибок, що робить його привабливою альтернативою класичним методам. Надано практичні рекомендації щодо вибору між PMM2 та класичними методами на основі коефіцієнта асиметрії залишків.

\textbf{Висновки.} PMM2 є першим застосуванням методу максимізації поліномів до оцінювання параметрів ARIMA моделей. Метод демонструє значні переваги перед класичними підходами для негаусових інновацій, зберігаючи обчислювальну ефективність та простоту імплементації. Напрямки подальших досліджень включають розширення на сезонні SARIMA моделі, інтеграцію з моделями волатильності GARCH, та розробку автоматичних процедур вибору порядку моделі.

\end{abstract}

\noindent\textbf{Ключові слова:} ARIMA моделі, метод максимізації поліномів, PMM2, негаусові інновації, оцінювання параметрів, асимптотична ефективність, часові ряди, асиметричні розподіли, Monte Carlo симуляції

\vspace{1em}

% ============================================
% ABSTRACT - ENGLISH
% ============================================
\begin{abstract}
\selectlanguage{english}

\textbf{Context.} Autoregressive Integrated Moving Average (ARIMA) models are among the most widely used tools for time series analysis in economics, finance, and related fields. Classical parameter estimation methods---Maximum Likelihood Estimation (MLE), Conditional Sum of Squares (CSS), and Ordinary Least Squares (OLS)---assume Gaussian innovations. However, this assumption is frequently violated in practice, particularly in financial and economic data exhibiting asymmetric distributions with heavy tails.

\textbf{Objective.} This study develops and investigates the application of the second-order Polynomial Maximization Method (PMM2) for estimating ARIMA(p,d,q) model parameters under non-Gaussian innovations. PMM2, developed by Y.P. Kunchenko, is a semi-parametric method that utilizes partial parameterization through higher-order moments and cumulants instead of full probability density specification.

\textbf{Methodology.} We developed a complete PMM2 algorithm for ARIMA models, incorporating series differencing, stationarity testing, and a Newton-Raphson iterative procedure for solving the PMM2 system of equations. Comprehensive Monte Carlo simulations with 2000 replications per configuration were conducted, spanning different sample sizes (N~$\in$~\{100, 200, 500, 1000\}) and four innovation distributions: Gaussian (control), Gamma $\Gamma(2,1)$ with $\gamma_3 \approx 1.41$, Lognormal with $\gamma_3 \approx 2.0$, and $\chi^2(3)$ with $\gamma_3 \approx 1.63$.

\textbf{Results.} Empirical results demonstrate that PMM2 provides substantial efficiency gains for asymmetric distributions. For an ARIMA(1,1,0) model with gamma-distributed innovations at N=500, we obtained relative efficiency RE=1.62 (corresponding to 40\% mean squared error reduction), for lognormal distribution RE=1.71 (41\% improvement), and for $\chi^2(3)$ RE=1.87 (47\% improvement). For Gaussian innovations, PMM2 exhibits efficiency close to OLS (RE~$\approx$~1.0), consistent with theory. Method efficiency increases with sample size and is stable for N~$\geq$~200.

\textbf{Practical Value.} The study demonstrates that PMM2 is an effective tool for analyzing time series with asymmetric innovations, commonly encountered in financial and economic data. The method provides substantial variance reduction in parameter estimates without requiring full error distribution specification, making it an attractive alternative to classical methods. Practical guidelines for choosing between PMM2 and classical methods based on residual skewness are provided.

\textbf{Conclusions.} PMM2 represents the first application of the polynomial maximization method to ARIMA parameter estimation. The method demonstrates significant advantages over classical approaches for non-Gaussian innovations while maintaining computational efficiency and implementation simplicity. Future research directions include extension to seasonal SARIMA models, integration with GARCH volatility models, and development of automatic model order selection procedures.

\end{abstract}

\noindent\textbf{Keywords:} ARIMA models, polynomial maximization method, non-Gaussian innovations, parameter estimation, asymptotic efficiency, time series analysis, skewed distributions, Monte Carlo simulation

\selectlanguage{ukrainian}

\newpage
\tableofcontents
\newpage

% ============================================
% SECTION 1: INTRODUCTION
% ============================================
\section{Вступ}
\label{sec:introduction}

\subsection{Актуальність Проблеми}
\label{subsec:motivation}

Моделі авторегресії та інтегрованого ковзного середнього (ARIMA) залишаються одним з найпоширеніших інструментів аналізу та прогнозування часових рядів у сучасній науці. Починаючи від піонерської роботи Box і Jenkins (1970), ARIMA моделі знайшли застосування у фінансовій економетриці, макроекономічному прогнозуванні, аналізі метеорологічних даних, медичній статистиці та багатьох інших галузях~\cite{box2015time,hyndman2021forecasting}.

Класичні методи оцінювання параметрів ARIMA моделей --- метод максимальної правдоподібності (MLE), метод умовної суми квадратів (CSS) та звичайний метод найменших квадратів (OLS) --- базуються на фундаментальному припущенні \textbf{гаусовості інновацій} (випадкових похибок). Це припущення забезпечує низку бажаних статистичних властивостей: асимптотичну ефективність оцінок, простоту обчислень та зрозумілу інференцію. Проте, практика аналізу реальних даних систематично демонструє порушення цього припущення.

Останні дослідження надають переконливі емпіричні свідчення негаусовості у різноманітних типах часових рядів:

\begin{itemize}
    \item \textbf{Фінансові часові ряди:} Доходності акцій, обмінні курси та волатильність демонструють асиметричні розподіли з важкими хвостами. Дослідження показують, що навіть після врахування волатильності через GARCH моделі, важкі хвости залишаються~\cite{viswanathan2003quantifying,kim2012approximation}. Нещодавнє дослідження Korean stock market підтвердило персистентність важких хвостів навіть після контролю за кризовими періодами та кластеризацією волатильності~\cite{kim2019fat}.

    \item \textbf{Економічні показники:} Ціни на сировинні товари, інфляційні дані та торговельні обсяги характеризуються значною асиметрією. Дослідження 15 економік за період 1851-1913 виявило сильний зв'язок між асиметрією цін на товари та інфляцією, при цьому до 48\% варіації інфляції пояснюється змінами цін на товари~\cite{jacks2024commodity}.

    \item \textbf{Екологічні та метеорологічні дані:} Вимірювання забруднення, опади, температурні аномалії та сонячна активність часто мають асиметричний характер з екстремальними значеннями. Verma et al. (2024) продемонстрували важкі хвости у даних сонячних спалахів та обговорили теоретичні межі прогнозування за умов важких хвостів~\cite{verma2024optimal}.

    \item \textbf{Високочастотні фінансові дані:} Mixed-stable моделі, застосовані до DAX компаній на 10-секундних інтервалах, виявили 43-82\% нульових змін (стагнаційні ефекти), що потребує спеціальних методів моделювання~\cite{slezak2023application,dedomenico2023modeling}.
\end{itemize}

Дуже свіжі дослідження 2025 року продовжують підтверджувати ці висновки. Markiewicz \& Wyłomańska (2021) показали, що SARIMAX моделі з Student-t інноваціями значно покращують прогнози для даних з важкими хвостами~\cite{markiewicz2021time}. У роботі ``Modeling Time Series with SARIMAX and Skew-Normal Errors'' (Mathematics MDPI, 2025) продемонстровано, що врахування асиметрії через skew-normal розподіл зменшує MAE до 0.40 та RMSE до 0.49 для сценаріїв з негативною асиметрією~\cite{saraiva2025modeling}.

\subsection{Обмеження Класичних Методів}
\label{subsec:limitations}

За умов порушення припущення гаусовості, класичні методи оцінювання параметрів ARIMA моделей зазнають суттєвих проблем:

\paragraph{Систематична зміщеність та неконсистентність.} Pötscher (1991) продемонстрував, що псевдо-максимізатори правдоподібності можуть поводитися драстично інакше, ніж локальні максимізатори, коли розподіл інновацій специфіковано невірно. Gaussian pseudo-likelihood може призводити до неконсистентних оцінок за умов розподільної неспецифікації~\cite{potscher1991noninvertibility}. Qi \& Fan (2010) показали, що non-Gaussian квазі-MLE страждає від неконсистентності, якщо квазі-правдоподібність не є справжнім розподілом, пропонуючи двокроковий non-Gaussian QMLE для досягнення консистентності з вищою ефективністю порівняно з Gaussian QMLE~\cite{qi2010non}.

\paragraph{Втрата статистичної ефективності.} Навіть коли оцінки залишаються консистентними, їх дисперсія може бути суттєво завищеною порівняно з оптимальними оцінками, адаптованими до справжнього розподілу інновацій. Zhang \& Sin (2012) показали, що граничні розподіли є сумішшю стабільних та гаусових процесів для near-unit root AR процесів з $\alpha$-стабільним шумом, демонструючи ускладнення за умов важких хвостів та близькості до одиничного кореня~\cite{zhang2012maximum}.

\paragraph{Зниження точності прогнозів.} Li et al. (2020) документували, що традиційні ARIMA моделі мають великі відхилення для високочастотного фінансового прогнозування, оскільки фінансові дані демонструють нерегулярні флуктуації, що потребують альтернативних підходів~\cite{li2020forecasting}. Dowe et al. (2025) у своїй дуже свіжій роботі показали, що гібридні ARFIMA-ANN підходи краще обробляють складну негаусову динаміку у фінансових та екологічних даних, при цьому використовуючи MML принцип для вибору моделі~\cite{dowe2025novel}.

\paragraph{Невірні довірчі інтервали.} Ledolter (1989) продемонстрував, що неврахування викидів збільшує середньоквадратичну похибку прогнозу та спричиняє зміщеність оцінених параметрів, з застосуваннями до даних цін акцій~\cite{ledolter1989inference}. Це призводить до недооцінки або переоцінки невизначеності прогнозів, що критично важливо для прийняття рішень.

\subsection{Існуючі Підходи: Короткий Огляд}
\label{subsec:existing_approaches}

У відповідь на проблему негаусовості у часових рядах, науковою спільнотою розроблено декілька альтернативних підходів:

\paragraph{Робастні методи оцінювання (M-estimators).} Започатковані класичною роботою Huber (1964)~\cite{huber1964robust}, M-estimators мінімізують робастні функції втрат, що менш чутливі до викидів та важких хвостів. Muler et al. (2009) запровадили BIP-ARMA моделі з MM-оцінками, що уникають поширення викидів через обмежені залишки, досягаючи консистентності та асимптотичної нормальності з ефективністю, порівнянною з MLE за нормальності~\cite{muler2009robust}. Reisen et al. (2024) запропонували M-Whittle estimator з встановленою властивістю консистентності, що добре працює з викидами та шумом з важкими хвостами~\cite{reisen2024robust}.

\paragraph{Квантильна регресія та LAD методи.} Katsouris (2023) надав комплексний огляд моделей квантильної регресії часових рядів, що охоплює стаціонарні та нестаціонарні випадки, з Bahadur представленнями для квантільних процесів та рівномірною інференцією у квантільній пороговій регресії~\cite{katsouris2023quantile}. Для ARMA моделей з нескінченною дисперсією, Peng \& Yao (2003), Ling (2005) та Zhu \& Ling (2015) запропонували зважену оцінку найменших абсолютних відхилень (WLADE), що є асимптотично нормальною та незміщеною зі стандартною швидкістю збіжності root-n навіть за відсутності скінченної дисперсії~\cite{peng2003least,ling2005self,zhu2015model}.

\paragraph{Специфікації з важкими хвостами.} Модифікація класичних ARIMA моделей шляхом заміни гаусових інновацій на розподіли з важкими хвостами (Student-t, Generalized Error Distribution, $\alpha$-stable distributions) дозволяє краще моделювати екстремальні події. Wong et al. (2009) розробили Student-t mixture autoregressive модель з вищою гнучкістю порівняно з Gaussian MAR, де ступені свободи є випадковими змінними, використовуючи EM алгоритм для оцінювання параметрів у Байєсовому фреймворку~\cite{wong2009student}. Нещодавнє дослідження 2024 року виявило, що skewed GED найбільш ефективний для фінансових часових рядів порівняно з normal, Student-t, GED та Skewed Student-t розподілами за метриками goodness-of-fit~\cite{palacios2024comparative}.

\paragraph{Байєсовські підходи.} Graves et al. (2014) запропонували систематичний підхід до Байєсовської інференції для ARFIMA моделей з новою апроксимативною правдоподібністю для ефективної інференції параметрів у процесах з довгою пам'яттю, що дозволяє інноваціям з широкого класу, включаючи $\alpha$-stable та t-розподіли~\cite{graves2014efficient}. Байєсовські методи також інтегрують невизначеність у всі параметри, забезпечуючи повну постеріорну інференцію замість точкових оцінок.

Кожен з цих підходів має свої переваги та обмеження. Робастні методи забезпечують стійкість до викидів, але можуть втрачати ефективність за умов помірних відхилень від нормальності. Квантільна регресія надає інформацію про різні частини розподілу, але не оптимізована для центральних оцінок параметрів. Специфікації з важкими хвостами потребують правильного вибору сімейства розподілів, що може бути проблематичним на практиці. Байєсовські методи є обчислювально інтенсивними, особливо для великих наборів даних.

\subsection{Метод Максимізації Поліномів: Альтернативний Підхід}
\label{subsec:pmm_intro}

Метод максимізації поліномів (Polynomial Maximization Method, PMM), розроблений українським вченим Ю.П. Кунченко, представляє альтернативну філософію статистичного оцінювання~\cite{kunchenko1991estimation,kunchenko2002polynomial}. На відміну від класичного методу максимальної правдоподібності, який потребує повної специфікації густини ймовірності, PMM базується на \textbf{частковій імовірнісній параметризації} через моменти та кумулянти вищих порядків.

Центральною конструкцією методу є максимізація стохастичного полінома порядку $S$ відносно параметрів моделі. Для PMM2 (порядок $S=2$), який оптимальний для асиметричних розподілів, використовуються моменти до 4-го порядку. Ключова ідея полягає в тому, що замість максимізації повної функції правдоподібності, метод максимізує вибіркову статистику в околі справжніх значень оцінюваних параметрів~\cite{kunchenko2002polynomial,kunchenko2006stochastic}.

Теоретична відносна ефективність PMM2 щодо OLS визначається коефіцієнтом~\cite{zabolotnii2018polynomial}:
\begin{equation}
\label{eq:relative_efficiency}
RE = \frac{\text{Var}(\hat{\theta}_{\text{OLS}})}{\text{Var}(\hat{\theta}_{\text{PMM2}})} = \frac{1}{1 - \frac{\gamma_3^2}{4+2\gamma_4}} = \frac{4 + 2\gamma_4}{4 + 2\gamma_4 - \gamma_3^2}
\end{equation}
де $\gamma_3$ --- коефіцієнт асиметрії (skewness), $\gamma_4$ --- коефіцієнт ексцесу (excess kurtosis). Це означає, що зменшення дисперсії пропорційне до квадрату асиметрії розподілу інновацій.

PMM метод успішно застосовувався до різноманітних задач статистичного оцінювання:

\begin{itemize}
    \item \textbf{Лінійна регресія:} Zabolotnii et al. (2018) продемонстрували застосування PMM2 до лінійної регресії з асиметричним розподілом похибок, досягаючи зменшення дисперсії на 15-35\% порівняно з OLS для gamma та lognormal розподілів~\cite{zabolotnii2018polynomial}.

    \item \textbf{Поліноміальна регресія:} Zabolotnii et al. (2021) розширили метод на поліноміальну регресію з розподілом експоненціальної потужності (generalized Gaussian distribution), підтверджуючи ефективність через Monte Carlo та bootstrap симуляції~\cite{zabolotnii2021estimating}.

    \item \textbf{Обробка сигналів:} Palahin \& Juhár (2016) застосували PMM до спільного оцінювання параметрів сигналу у негаусовому шумі, показавши, що нелінійна обробка через кумулянти третього та вищих порядків може зменшити дисперсію спільного оцінювання параметрів порівняно з конвенційними методами~\cite{palahin2016joint}.

    \item \textbf{Метрологічні вимірювання:} Warsza \& Zabolotnii (2017, 2018) використали PMM для оцінювання параметрів вимірювань з негаусовими симетричними та асиметричними розподілами даних, розробляючи методику PMM3 для симетричних розподілів~\cite{warsza2017polynomial,zabolotnii2020estimation}.
\end{itemize}

Варто відзначити, що PMM метод позиціонується між класичним методом моментів та методом максимальної правдоподібності. На відміну від методу моментів, PMM використовує кумулянтний опис та максимізацію стохастичного полінома. На відміну від узагальненого методу моментів (GMM) Hansen (1982), який мінімізує зважену суму квадратів відхилень між вибірковими та популяційними моментами, PMM максимізує стохастичний поліном, явно використовуючи кумулянти порядку $\geq 3$~\cite{chepinoga2014polynomial}. Дослідження poly-Gaussian моделей дійшло висновку про ``велику перевагу методу Кунченка над методом моментів та його апроксимацію ефективності до методу максимальної правдоподібності''.

\subsection{Дослідницька Прогалина та Внесок Роботи}
\label{subsec:research_gap}

Незважаючи на успішне застосування PMM2 до регресійних задач та обробки сигналів, його систематичне використання для оцінювання параметрів ARIMA моделей з негаусовими інноваціями залишається недостатньо дослідженим. Існує кілька ключових дослідницьких прогалин:

\paragraph{Відсутність кумулянт-базованих методів для часових рядів.} Хоча кумулянти вищих порядків широко використовуються в обробці сигналів та спектральному аналізі, їх застосування до оцінювання параметрів ARIMA моделей обмежене. Більшість методів для негаусових ARIMA зосереджені на робастних функціях втрат або специфікації розподілів, але не на явній експлуатації кумулянтної структури.

\paragraph{Недостатня увага до асиметричних інновацій.} Більшість робіт з негаусових ARIMA фокусуються на симетричних розподілах з важкими хвостами (Student-t, GED). Асиметричні розподіли, які PMM2 спеціально адресує, отримують менше уваги, незважаючи на їх емпіричну поширеність у фінансових доходностях та економічних показниках.

\paragraph{Методологічний розрив між регіональними дослідницькими спільнотами.} Метод Кунченка, незважаючи на сильні теоретичні основи та успішні застосування в Східній Європі, залишається малознайомим у західній літературі з часових рядів. Ця робота має на меті інтегрувати східноєвропейську статистичну методологію з західною економетричною літературою часових рядів (Box-Jenkins, ARIMA).

\paragraph{Відсутність порівняльних досліджень ефективності.} Порівняльні дослідження зазвичай порівнюють MLE, M-estimators, LAD та квантільну регресію. Порівняння ефективності кумулянт-базованих методів, таких як PMM, відносно цих альтернатив відсутні для ARIMA моделей.

Дане дослідження заповнює ці прогалини шляхом:

\begin{enumerate}
    \item \textbf{Розробки повної методології} застосування PMM2 до ARIMA(p,d,q) моделей, включаючи обробку диференціювання, перевірку стаціонарності та адаптацію алгоритму оцінювання до структури часових рядів.

    \item \textbf{Створення повної Python імплементації} методу з відкритим вихідним кодом для забезпечення відтворюваності та практичного використання науковою спільнотою.

    \item \textbf{Проведення comprehensive Monte Carlo симуляцій} (2000+ ітерацій) для верифікації ефективності методу при різних розмірах вибірки (N = 100, 200, 500, 1000) та типах розподілів інновацій (gamma, lognormal, chi-squared, Gaussian).

    \item \textbf{Систематичного порівняння} з існуючими методами (CSS, OLS) за метриками bias, variance, MSE, relative efficiency та variance reduction для встановлення умов, за яких PMM2 забезпечує переваги.

    \item \textbf{Формулювання практичних рекомендацій} щодо вибору методу оцінювання на основі кумулянтних коефіцієнтів залишків ($\gamma_3$, $\gamma_4$) та характеристик даних.
\end{enumerate}

\subsection{Структура Статті}
\label{subsec:structure}

Решта статті організована наступним чином:

\begin{itemize}
    \item \textbf{Розділ~\ref{sec:methodology}} надає детальну методологію PMM2 для ARIMA моделей, включаючи математичну формулювання, алгоритм оцінювання та асимптотичну теорію.

    \item \textbf{Розділ~\ref{sec:empirical}} описує дизайн Monte Carlo симуляцій та представляє емпіричні результати для різних конфігурацій.

    \item \textbf{Розділ~\ref{sec:discussion}} обговорює інтерпретацію результатів, практичні рекомендації, обмеження та напрямки подальших досліджень.

    \item \textbf{Розділ~\ref{sec:conclusion}} підсумовує основні висновки та внески дослідження.
\end{itemize}

% ============================================
% SECTION 2: METHODOLOGY
% ============================================
\section{Методологія}
\label{sec:methodology}

У цьому розділі ми надаємо повну методологію застосування методу максимізації поліномів другого порядку (PMM2) до оцінювання параметрів ARIMA моделей з негаусовими інноваціями. Спочатку формулюємо ARIMA модель та класичні методи оцінювання, потім розглядаємо теоретичні основи PMM2, адаптуємо метод до контексту часових рядів, та надаємо алгоритм реалізації з асимптотичною теорією.

\subsection{ARIMA Моделі: Основи та Класичне Оцінювання}
\label{subsec:arima_basics}

\subsubsection{Визначення ARIMA(p,d,q) Моделі}

Авторегресійна інтегрована модель ковзного середнього ARIMA(p,d,q) описує часовий ряд $\{y_t\}_{t=1}^T$ через три компоненти: авторегресійну (AR) порядку $p$, диференціювання порядку $d$, та ковзного середнього (MA) порядку $q$.

\begin{definition}[ARIMA(p,d,q) модель]
Часовий ряд $\{y_t\}$ слідує ARIMA(p,d,q) моделі, якщо $d$-та різниця ряду
\begin{equation}
\label{eq:differencing}
z_t = \Delta^d y_t = (1-B)^d y_t
\end{equation}
задовольняє стаціонарну та оборотну ARMA(p,q) модель:
\begin{equation}
\label{eq:arma}
\Phi(B) z_t = \Theta(B) \varepsilon_t
\end{equation}
де $B$ --- оператор зсуву ($B y_t = y_{t-1}$), та
\begin{align}
\Phi(B) &= 1 - \phi_1 B - \phi_2 B^2 - \cdots - \phi_p B^p \label{eq:ar_poly} \\
\Theta(B) &= 1 + \theta_1 B + \theta_2 B^2 + \cdots + \theta_q B^q \label{eq:ma_poly}
\end{align}
є поліномами авторегресії та ковзного середнього відповідно, а $\{\varepsilon_t\}$ --- послідовність незалежних однаково розподілених (i.i.d.) інновацій з нульовим середнім та дисперсією $\sigma^2$.
\end{definition}

Еквівалентно, ARIMA модель може бути записана у явній формі:
\begin{equation}
\label{eq:arima_explicit}
y_t = \sum_{j=1}^{d} \binom{d}{j} (-1)^{j+1} y_{t-j} + \sum_{i=1}^{p} \phi_i z_{t-i} + \varepsilon_t + \sum_{k=1}^{q} \theta_k \varepsilon_{t-k}
\end{equation}

\paragraph{Умови стаціонарності та оборотності.}

\begin{itemize}
    \item \textbf{Стаціонарність:} Корені характеристичного рівняння $\Phi(z) = 0$ лежать поза одиничним колом: $|z_i| > 1$ для всіх $i = 1, \ldots, p$.

    \item \textbf{Оборотність:} Корені характеристичного рівняння $\Theta(z) = 0$ лежать поза одиничним колом: $|z_j| > 1$ для всіх $j = 1, \ldots, q$.
\end{itemize}

\subsubsection{Класичні Методи Оцінювання}

Нехай $\boldsymbol{\theta} = (\phi_1, \ldots, \phi_p, \theta_1, \ldots, \theta_q)^\top$ --- вектор параметрів розміру $k = p + q$.

\paragraph{Метод умовної суми квадратів (CSS).}

CSS метод мінімізує умовну суму квадратів залишків:
\begin{equation}
\label{eq:css}
\hat{\boldsymbol{\theta}}_{\text{CSS}} = \arg\min_{\boldsymbol{\theta}} S(\boldsymbol{\theta}) = \arg\min_{\boldsymbol{\theta}} \sum_{t=p+1}^{T} \varepsilon_t^2(\boldsymbol{\theta})
\end{equation}
де $\varepsilon_t(\boldsymbol{\theta})$ --- залишки, обчислені рекурсивно з початковими умовами $\varepsilon_t = 0$ для $t \leq 0$ та $z_t = 0$ для $t \leq 0$.

\paragraph{Звичайний метод найменших квадратів (OLS).}

Для авторегресійної частини, OLS оцінює параметри через лінійну регресію:
\begin{equation}
\label{eq:ols}
\hat{\boldsymbol{\phi}}_{\text{OLS}} = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{z}
\end{equation}
де $\mathbf{z} = (z_{p+1}, \ldots, z_T)^\top$ та $\mathbf{X}$ --- матриця регресорів розміру $(T-p) \times p$ з елементами $X_{ti} = z_{t-i}$.

\paragraph{Метод максимальної правдоподібності (MLE).}

За припущення гаусовості інновацій $\varepsilon_t \sim \mathcal{N}(0, \sigma^2)$, MLE максимізує функцію правдоподібності:
\begin{equation}
\label{eq:mle}
\hat{\boldsymbol{\theta}}_{\text{MLE}} = \arg\max_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta} \mid \mathbf{y}) = \arg\max_{\boldsymbol{\theta}} \left\{ -\frac{T}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} \varepsilon_t^2(\boldsymbol{\theta}) \right\}
\end{equation}

За умови нормальності, MLE є асимптотично ефективним, консистентним та асимптотично нормальним:
\begin{equation}
\label{eq:mle_asymptotic}
\sqrt{T}(\hat{\boldsymbol{\theta}}_{\text{MLE}} - \boldsymbol{\theta}_0) \xrightarrow{d} \mathcal{N}\left(0, \sigma^2 \left[\mathbb{E}\left(\frac{\partial \varepsilon_t}{\partial \boldsymbol{\theta}} \frac{\partial \varepsilon_t}{\partial \boldsymbol{\theta}^\top}\right)\right]^{-1}\right)
\end{equation}

Однак, ці властивості порушуються за умов негаусовості інновацій.

\subsection{Теоретичні Основи Методу Максимізації Поліномів}
\label{subsec:pmm_theory}

\subsubsection{Стохастичні Поліноми та Кумулянтний Опис}

Метод максимізації поліномів базується на концепції стохастичних поліномів, що є поліноміальними функціями випадкових величин з коефіцієнтами, що залежать від параметрів моделі.

\begin{definition}[Стохастичний поліном порядку $S$]
Для випадкової величини $\xi$ та параметра $\theta$, стохастичний поліном порядку $S$ визначається як:
\begin{equation}
\label{eq:stochastic_polynomial}
P_S(\xi; \theta) = \sum_{s=0}^{S} a_s(\theta) \xi^s
\end{equation}
де $a_s(\theta)$ --- детерміновані коефіцієнти, що залежать від параметра $\theta$.
\end{definition}

Ключова ідея PMM полягає в побудові таких коефіцієнтів $a_s(\theta)$, що математичне сподівання стохастичного полінома досягає максимуму в околі справжнього значення параметра $\theta_0$.

\paragraph{Кумулянти та їх властивості.}

Нехай $\kappa_r$ позначає $r$-й кумулянт випадкової величини $\xi$. Кумулянти мають наступні властивості:

\begin{itemize}
    \item $\kappa_1 = \mathbb{E}[\xi]$ (середнє)
    \item $\kappa_2 = \text{Var}(\xi)$ (дисперсія)
    \item $\kappa_3 = \mathbb{E}[(\xi - \mu)^3]$ (третій центральний момент, пов'язаний з асиметрією)
    \item $\kappa_4 = \mathbb{E}[(\xi - \mu)^4] - 3\kappa_2^2$ (четвертий кумулянт, пов'язаний з ексцесом)
\end{itemize}

Стандартизовані кумулянти (кумулянтні коефіцієнти) визначаються як:
\begin{align}
\gamma_3 &= \frac{\kappa_3}{\kappa_2^{3/2}} \quad \text{(коефіцієнт асиметрії)} \label{eq:skewness} \\
\gamma_4 &= \frac{\kappa_4}{\kappa_2^{2}} \quad \text{(коефіцієнт ексцесу)} \label{eq:kurtosis}
\end{align}

Для гаусового розподілу $\gamma_3 = 0$ та $\gamma_4 = 0$. Відхилення від нуля вказують на негаусовість.

\subsubsection{PMM2 для Асиметричних Розподілів}

Для асиметричних розподілів ($\gamma_3 \neq 0$), оптимальним є стохастичний поліном другого порядку (PMM2).

\begin{theorem}[PMM2 для простої оцінки параметра]
\label{thm:pmm2_basic}
Розглянемо оцінювання параметра локації $\theta$ випадкової величини $\xi = \theta + \varepsilon$, де $\varepsilon$ --- похибка з нульовим середнім, дисперсією $\sigma^2$, та кумулянтами $\kappa_3 \neq 0$, $\kappa_4$. Стохастичний поліном другого порядку
\begin{equation}
\label{eq:pmm2_polynomial}
P_2(\xi; \theta) = a_0(\theta) + a_1(\theta) \xi + a_2(\theta) \xi^2
\end{equation}
з коефіцієнтами
\begin{align}
a_0(\theta) &= -\frac{\kappa_3}{2(4\kappa_2 + 2\kappa_4)} \theta^2 + \text{const} \label{eq:a0} \\
a_1(\theta) &= \frac{\kappa_3}{4\kappa_2 + 2\kappa_4} \theta \label{eq:a1} \\
a_2(\theta) &= -\frac{\kappa_3}{2(4\kappa_2 + 2\kappa_4)} \label{eq:a2}
\end{align}
має властивість, що $\mathbb{E}[P_2(\xi; \theta)]$ досягає максимуму при $\theta = \theta_0$.
\end{theorem}

\paragraph{Оцінювач PMM2.}

PMM2 оцінювач отримується максимізацією вибіркового середнього стохастичного полінома:
\begin{equation}
\label{eq:pmm2_estimator}
\hat{\theta}_{\text{PMM2}} = \arg\max_{\theta} \frac{1}{n} \sum_{i=1}^{n} P_2(\xi_i; \theta)
\end{equation}

Умова першого порядку для максимізації:
\begin{equation}
\label{eq:pmm2_foc}
\frac{\partial}{\partial \theta} \left[ \frac{1}{n} \sum_{i=1}^{n} P_2(\xi_i; \theta) \right] = 0
\end{equation}

Підставляючи вирази для коефіцієнтів~\eqref{eq:a0}--\eqref{eq:a2} та спрощуючи, отримуємо:
\begin{equation}
\label{eq:pmm2_solution}
\hat{\theta}_{\text{PMM2}} = \frac{\sum_{i=1}^{n} \xi_i - \frac{\kappa_3}{4\kappa_2 + 2\kappa_4} \sum_{i=1}^{n} \xi_i^2}{n - \frac{\kappa_3}{4\kappa_2 + 2\kappa_4} \sum_{i=1}^{n} \xi_i}
\end{equation}

Для практичного застосування, кумулянти $\kappa_2$, $\kappa_3$, $\kappa_4$ замінюються їх вибірковими оцінками.

\subsubsection{Асимптотична Ефективність PMM2}

\begin{theorem}[Відносна ефективність PMM2 щодо OLS]
\label{thm:relative_efficiency}
За умови, що інновації $\varepsilon_t$ мають скінченні моменти до четвертого порядку включно, відносна ефективність PMM2 оцінювача щодо OLS визначається як:
\begin{equation}
\label{eq:re_pmm2_ols}
RE_{\text{PMM2/OLS}} = \frac{\text{Var}(\hat{\theta}_{\text{OLS}})}{\text{Var}(\hat{\theta}_{\text{PMM2}})} = \frac{4 + 2\gamma_4}{4 + 2\gamma_4 - \gamma_3^2}
\end{equation}
де $\gamma_3$ та $\gamma_4$ --- стандартизовані коефіцієнти асиметрії та ексцесу інновацій відповідно.
\end{theorem}

\begin{proof}[Ескіз доведення]
Доведення базується на розкладі Тейлора умови першого порядку~\eqref{eq:pmm2_foc} в околі справжнього значення параметра та обчисленні асимптотичної дисперсії через інформаційну матрицю Фішера для часткового кумулянтного опису. Детальне доведення наведено в~\cite{kunchenko2002polynomial,zabolotnii2018polynomial}.
\end{proof}

\paragraph{Інтерпретація відносної ефективності.}

\begin{itemize}
    \item Для гаусових інновацій ($\gamma_3 = 0$, $\gamma_4 = 0$): $RE = 1$, тобто PMM2 еквівалентний OLS.

    \item Для асиметричних розподілів ($\gamma_3 \neq 0$): $RE > 1$, тобто PMM2 має меншу дисперсію.

    \item Відносна ефективність зростає квадратично з асиметрією: $RE \approx 1 + \frac{\gamma_3^2}{4}$ для малих $\gamma_3$ та $\gamma_4 \approx 0$.

    \item Наприклад, для $\gamma_3 = 1.5$ та $\gamma_4 = 3$: $RE = 10/(10 - 2.25) \approx 1.29$, що відповідає 22\% зменшенню дисперсії.
\end{itemize}

\subsection{PMM2 для ARIMA Моделей: Адаптація Методу}
\label{subsec:pmm2_arima}

\subsubsection{Мотивація: Чому Класичний PMM2 Потребує Адаптації}

Пряме застосування PMM2 до ARIMA моделей стикається з декількома викликами:

\begin{enumerate}
    \item \textbf{Нестаціонарність:} Диференціювання вносить додаткові джерела варіації.

    \item \textbf{Часова залежність:} Інновації $\varepsilon_t$ не спостерігаються безпосередньо, а обчислюються рекурсивно через залишки.

    \item \textbf{Багатопараметричність:} ARIMA моделі мають $k = p + q$ параметрів, що потребує багатовимірної оптимізації.

    \item \textbf{Ідентифікованість:} Необхідно забезпечити умови стаціонарності та оборотності.
\end{enumerate}

\subsubsection{Формулювання PMM2 для ARIMA}

Розглянемо ARIMA(p,d,q) модель з вектором параметрів $\boldsymbol{\theta} = (\phi_1, \ldots, \phi_p, \theta_1, \ldots, \theta_q)^\top$.

\paragraph{Крок 1: Диференціювання.}

Застосовуємо диференціювання порядку $d$ до вихідного ряду:
\begin{equation}
\label{eq:differenced_series}
z_t = \Delta^d y_t, \quad t = d+1, \ldots, T
\end{equation}

Це дає стаціонарний ряд довжини $n = T - d$.

\paragraph{Крок 2: Обчислення залишків.}

Для заданого вектора параметрів $\boldsymbol{\theta}$, залишки обчислюються рекурсивно:
\begin{equation}
\label{eq:residuals}
\varepsilon_t(\boldsymbol{\theta}) = z_t - \sum_{i=1}^{p} \phi_i z_{t-i} - \sum_{k=1}^{q} \theta_k \varepsilon_{t-k}(\boldsymbol{\theta})
\end{equation}
з початковими умовами $\varepsilon_t = 0$ для $t \leq 0$ та $z_t = \bar{z}$ для $t \leq 0$, де $\bar{z} = \frac{1}{n}\sum_{t=1}^{n} z_t$.

\paragraph{Крок 3: Оцінювання вибіркових кумулянтів.}

Для заданого $\boldsymbol{\theta}$, обчислюємо вибіркові кумулянти залишків:
\begin{align}
\hat{\kappa}_2(\boldsymbol{\theta}) &= \frac{1}{n} \sum_{t=1}^{n} \varepsilon_t^2(\boldsymbol{\theta}) \label{eq:sample_k2} \\
\hat{\kappa}_3(\boldsymbol{\theta}) &= \frac{1}{n} \sum_{t=1}^{n} \varepsilon_t^3(\boldsymbol{\theta}) \label{eq:sample_k3} \\
\hat{\kappa}_4(\boldsymbol{\theta}) &= \frac{1}{n} \sum_{t=1}^{n} \varepsilon_t^4(\boldsymbol{\theta}) - 3\hat{\kappa}_2^2(\boldsymbol{\theta}) \label{eq:sample_k4}
\end{align}

\paragraph{Крок 4: Побудова стохастичного полінома.}

Стохастичний поліном PMM2 для багатопараметричної моделі:
\begin{equation}
\label{eq:pmm2_multivariate}
P_2(\boldsymbol{\varepsilon}; \boldsymbol{\theta}) = \sum_{t=1}^{n} \left[ a_0 + a_1(\boldsymbol{\theta}) \varepsilon_t(\boldsymbol{\theta}) + a_2(\boldsymbol{\theta}) \varepsilon_t^2(\boldsymbol{\theta}) \right]
\end{equation}
де коефіцієнти визначаються через вибіркові кумулянти:
\begin{align}
a_0 &= \text{const} \label{eq:a0_arima} \\
a_1(\boldsymbol{\theta}) &= \frac{\hat{\kappa}_3(\boldsymbol{\theta})}{4\hat{\kappa}_2(\boldsymbol{\theta}) + 2\hat{\kappa}_4(\boldsymbol{\theta})} \label{eq:a1_arima} \\
a_2(\boldsymbol{\theta}) &= -\frac{\hat{\kappa}_3(\boldsymbol{\theta})}{2(4\hat{\kappa}_2(\boldsymbol{\theta}) + 2\hat{\kappa}_4(\boldsymbol{\theta}))} \label{eq:a2_arima}
\end{align}

\paragraph{Крок 5: Оцінювач PMM2 для ARIMA.}

PMM2 оцінювач для ARIMA визначається як:
\begin{equation}
\label{eq:pmm2_arima_estimator}
\hat{\boldsymbol{\theta}}_{\text{PMM2}} = \arg\max_{\boldsymbol{\theta} \in \Theta} P_2(\boldsymbol{\varepsilon}; \boldsymbol{\theta})
\end{equation}
де $\Theta$ --- простір параметрів, що задовольняє умови стаціонарності та оборотності.

Еквівалентно, максимізація стохастичного полінома зводиться до розв'язання системи нелінійних рівнянь:
\begin{equation}
\label{eq:pmm2_system}
\frac{\partial P_2(\boldsymbol{\varepsilon}; \boldsymbol{\theta})}{\partial \boldsymbol{\theta}} = \mathbf{0}
\end{equation}

\subsubsection{Градієнт та Гессіан для Ньютона-Рафсона}

Для ефективного розв'язання системи~\eqref{eq:pmm2_system}, використовуємо метод Ньютона-Рафсона, що потребує градієнта та Гессіана цільової функції.

\paragraph{Градієнт.}

$j$-й компонент градієнта:
\begin{equation}
\label{eq:gradient_j}
\frac{\partial P_2}{\partial \theta_j} = \sum_{t=1}^{n} \left[ a_1 \frac{\partial \varepsilon_t}{\partial \theta_j} + 2 a_2 \varepsilon_t \frac{\partial \varepsilon_t}{\partial \theta_j} + \frac{\partial a_1}{\partial \theta_j} \varepsilon_t + \frac{\partial a_2}{\partial \theta_j} \varepsilon_t^2 \right]
\end{equation}

де $\frac{\partial \varepsilon_t}{\partial \theta_j}$ обчислюється рекурсивно з~\eqref{eq:residuals}:
\begin{equation}
\label{eq:residual_derivative}
\frac{\partial \varepsilon_t}{\partial \theta_j} = \begin{cases}
-z_{t-j} - \sum_{k=1}^{q} \theta_k \frac{\partial \varepsilon_{t-k}}{\partial \phi_j} & \text{якщо } \theta_j = \phi_j \text{ (AR параметр)} \\
-\varepsilon_{t-j+p} - \sum_{k=1}^{q} \theta_k \frac{\partial \varepsilon_{t-k}}{\partial \theta_j} & \text{якщо } \theta_j \text{ (MA параметр)}
\end{cases}
\end{equation}

\paragraph{Гессіан.}

Елемент Гессіана:
\begin{equation}
\label{eq:hessian_jl}
\frac{\partial^2 P_2}{\partial \theta_j \partial \theta_l} = \sum_{t=1}^{n} \left[ a_1 \frac{\partial^2 \varepsilon_t}{\partial \theta_j \partial \theta_l} + 2 a_2 \left( \frac{\partial \varepsilon_t}{\partial \theta_j} \frac{\partial \varepsilon_t}{\partial \theta_l} + \varepsilon_t \frac{\partial^2 \varepsilon_t}{\partial \theta_j \partial \theta_l} \right) + \cdots \right]
\end{equation}

На практиці, часто використовується наближення Гессіана або метод квазі-Ньютона (BFGS) для уникнення обчислення других похідних.

\subsection{Алгоритм Оцінювання PMM2 для ARIMA}
\label{subsec:algorithm}

\begin{algorithm}[H]
\caption{PMM2 для ARIMA(p,d,q)}
\label{alg:pmm2_arima}
\begin{algorithmic}[1]
\REQUIRE Часовий ряд $\{y_t\}_{t=1}^T$, порядки $(p, d, q)$
\ENSURE PMM2 оцінки параметрів $\hat{\boldsymbol{\theta}}_{\text{PMM2}}$

\STATE \textbf{Крок 1: Попередня обробка}
\STATE Застосувати диференціювання: $z_t \leftarrow \Delta^d y_t$ для $t = d+1, \ldots, T$
\STATE Обчислити $n \leftarrow T - d$
\STATE Обчислити середнє: $\bar{z} \leftarrow \frac{1}{n}\sum_{t=1}^{n} z_t$

\STATE \textbf{Крок 2: Ініціалізація}
\STATE Отримати початкову оцінку $\boldsymbol{\theta}^{(0)}$ за допомогою CSS або OLS
\STATE Встановити лічильник ітерацій: $k \leftarrow 0$
\STATE Встановити критерій збіжності: $\epsilon \leftarrow 10^{-6}$

\STATE \textbf{Крок 3: Ітераційна процедура Ньютона-Рафсона}
\REPEAT
    \STATE $k \leftarrow k + 1$

    \STATE \textit{3.1. Обчислити залишки} $\varepsilon_t(\boldsymbol{\theta}^{(k-1)})$ за формулою~\eqref{eq:residuals}

    \STATE \textit{3.2. Обчислити вибіркові кумулянти} $\hat{\kappa}_2, \hat{\kappa}_3, \hat{\kappa}_4$ за формулами~\eqref{eq:sample_k2}--\eqref{eq:sample_k4}

    \STATE \textit{3.3. Обчислити коефіцієнти} $a_1, a_2$ за формулами~\eqref{eq:a1_arima}--\eqref{eq:a2_arima}

    \STATE \textit{3.4. Обчислити градієнт} $\mathbf{g}^{(k)} = \nabla_{\boldsymbol{\theta}} P_2(\boldsymbol{\varepsilon}; \boldsymbol{\theta}^{(k-1)})$ за формулою~\eqref{eq:gradient_j}

    \STATE \textit{3.5. Обчислити Гессіан} $\mathbf{H}^{(k)} = \nabla^2_{\boldsymbol{\theta}} P_2(\boldsymbol{\varepsilon}; \boldsymbol{\theta}^{(k-1)})$ або BFGS апроксимацію

    \STATE \textit{3.6. Оновити параметри:} $\boldsymbol{\theta}^{(k)} \leftarrow \boldsymbol{\theta}^{(k-1)} - (\mathbf{H}^{(k)})^{-1} \mathbf{g}^{(k)}$

    \STATE \textit{3.7. Перевірити обмеження:} Якщо $\boldsymbol{\theta}^{(k)}$ порушує стаціонарність/оборотність, проектувати на допустимий простір

\UNTIL $\|\boldsymbol{\theta}^{(k)} - \boldsymbol{\theta}^{(k-1)}\| < \epsilon$ або $k > k_{\max}$

\STATE \textbf{Крок 4: Фінальні обчислення}
\STATE Повернути $\hat{\boldsymbol{\theta}}_{\text{PMM2}} \leftarrow \boldsymbol{\theta}^{(k)}$
\STATE Обчислити оцінку дисперсії: $\hat{\sigma}^2 \leftarrow \hat{\kappa}_2(\hat{\boldsymbol{\theta}}_{\text{PMM2}})$

\RETURN $\hat{\boldsymbol{\theta}}_{\text{PMM2}}, \hat{\sigma}^2$
\end{algorithmic}
\end{algorithm}

\paragraph{Обчислювальна складність.}

\begin{itemize}
    \item \textbf{Обчислення залишків:} $O(nk)$ операцій на ітерацію, де $k = p + q$.

    \item \textbf{Обчислення кумулянтів:} $O(n)$ операцій на ітерацію.

    \item \textbf{Обчислення градієнта:} $O(nk)$ операцій.

    \item \textbf{Обчислення Гессіана:} $O(nk^2)$ операцій (або $O(k^2)$ для BFGS апроксимації).

    \item \textbf{Розв'язання системи:} $O(k^3)$ операцій для обернення Гессіана.

    \item \textbf{Загальна складність:} $O(I \cdot nk^2)$, де $I$ --- кількість ітерацій (типово $I = 10$--$50$).
\end{itemize}

Порівняно з класичним MLE, PMM2 має подібну обчислювальну складність, оскільки обидва методи потребують ітеративної оптимізації з обчисленням градієнтів та Гессіанів.

\subsection{Асимптотичні Властивості PMM2 для ARIMA}
\label{subsec:asymptotic_theory}

\subsubsection{Консистентність}

\begin{theorem}[Консистентність PMM2]
\label{thm:consistency}
За умови, що:
\begin{enumerate}
    \item ARIMA(p,d,q) модель правильно специфікована,
    \item Інновації $\varepsilon_t$ є i.i.d. з нульовим середнім, скінченною дисперсією $\sigma^2 < \infty$, та скінченними моментами до четвертого порядку включно,
    \item Справжній вектор параметрів $\boldsymbol{\theta}_0$ лежить у внутрішності компактного простору параметрів $\Theta$,
    \item Умови стаціонарності та оборотності виконуються,
\end{enumerate}
PMM2 оцінювач $\hat{\boldsymbol{\theta}}_{\text{PMM2}}$ є консистентним:
\begin{equation}
\label{eq:consistency}
\hat{\boldsymbol{\theta}}_{\text{PMM2}} \xrightarrow{p} \boldsymbol{\theta}_0 \quad \text{при } n \to \infty
\end{equation}
\end{theorem}

\begin{proof}[Ескіз доведення]
Доведення базується на застосуванні теорем про M-оцінки для часових рядів. Ключові кроки:
\begin{enumerate}
    \item Показати, що цільова функція $P_2(\boldsymbol{\varepsilon}; \boldsymbol{\theta})/n$ збігається рівномірно до детермінованого ліміту $Q(\boldsymbol{\theta})$ за законом великих чисел для залежних даних (ергодична теорема).

    \item Показати, що $Q(\boldsymbol{\theta})$ має єдиний максимум в $\boldsymbol{\theta}_0$.

    \item Застосувати теорему 2.1 з White (1994) для M-оцінок часових рядів.
\end{enumerate}
Детальне доведення вимагає перевірки умов рівномірної збіжності та ідентифікації, що є стандартною процедурою для часових рядів.
\end{proof}

\subsubsection{Асимптотична Нормальність}

\begin{theorem}[Асимптотична нормальність PMM2]
\label{thm:asymptotic_normality}
За умовами Теореми~\ref{thm:consistency}, PMM2 оцінювач є асимптотично нормальним:
\begin{equation}
\label{eq:asymptotic_normality}
\sqrt{n}(\hat{\boldsymbol{\theta}}_{\text{PMM2}} - \boldsymbol{\theta}_0) \xrightarrow{d} \mathcal{N}(0, \boldsymbol{\Sigma}_{\text{PMM2}})
\end{equation}
де асимптотична коваріаційна матриця:
\begin{equation}
\label{eq:asymptotic_covariance}
\boldsymbol{\Sigma}_{\text{PMM2}} = \mathbf{A}^{-1} \mathbf{B} (\mathbf{A}^{-1})^\top
\end{equation}
з матрицями:
\begin{align}
\mathbf{A} &= \mathbb{E}\left[ -\frac{\partial^2 P_2(\varepsilon_t; \boldsymbol{\theta}_0)}{\partial \boldsymbol{\theta} \partial \boldsymbol{\theta}^\top} \right] \label{eq:matrix_A} \\
\mathbf{B} &= \mathbb{E}\left[ \frac{\partial P_2(\varepsilon_t; \boldsymbol{\theta}_0)}{\partial \boldsymbol{\theta}} \frac{\partial P_2(\varepsilon_t; \boldsymbol{\theta}_0)}{\partial \boldsymbol{\theta}^\top} \right] \label{eq:matrix_B}
\end{align}
\end{theorem}

\paragraph{Оцінювання асимптотичної коваріації.}

На практиці, асимптотична коваріаційна матриця оцінюється як:
\begin{equation}
\label{eq:estimated_covariance}
\hat{\boldsymbol{\Sigma}}_{\text{PMM2}} = \hat{\mathbf{A}}^{-1} \hat{\mathbf{B}} (\hat{\mathbf{A}}^{-1})^\top
\end{equation}
де $\hat{\mathbf{A}}$ та $\hat{\mathbf{B}}$ --- вибіркові аналоги матриць~\eqref{eq:matrix_A}--\eqref{eq:matrix_B}, обчислені при $\boldsymbol{\theta} = \hat{\boldsymbol{\theta}}_{\text{PMM2}}$.

Стандартні похибки параметрів:
\begin{equation}
\label{eq:standard_errors}
\text{SE}(\hat{\theta}_j) = \sqrt{\frac{[\hat{\boldsymbol{\Sigma}}_{\text{PMM2}}]_{jj}}{n}}
\end{equation}

\subsubsection{Відносна Ефективність для ARIMA}

Для багатопараметричних ARIMA моделей, відносна ефективність PMM2 щодо OLS може бути визначена через детермінанти або сліди коваріаційних матриць:

\begin{equation}
\label{eq:re_arima_det}
RE_{\text{det}} = \left( \frac{|\boldsymbol{\Sigma}_{\text{OLS}}|}{|\boldsymbol{\Sigma}_{\text{PMM2}}|} \right)^{1/k}
\end{equation}

або

\begin{equation}
\label{eq:re_arima_trace}
RE_{\text{trace}} = \frac{\text{tr}(\boldsymbol{\Sigma}_{\text{OLS}})}{\text{tr}(\boldsymbol{\Sigma}_{\text{PMM2}})}
\end{equation}

Для простих ARIMA моделей (наприклад, ARIMA(1,1,0)), відносна ефективність добре апроксимується формулою~\eqref{eq:relative_efficiency}.

\subsection{Практичні Аспекти Реалізації}
\label{subsec:implementation}

\subsubsection{Вибір Початкових Значень}

Якість збіжності методу Ньютона-Рафсона суттєво залежить від початкових значень. Рекомендуємо наступну стратегію:

\begin{enumerate}
    \item \textbf{Метод Юла-Вокера} для AR компоненти для отримання початкових значень $\phi_1^{(0)}, \ldots, \phi_p^{(0)}$.

    \item \textbf{Conditional Sum of Squares (CSS)} для повної ARIMA моделі.

    \item \textbf{Перевірка стаціонарності:} Обчислити корені характеристичного полінома $\Phi(z) = 0$ та переконатися, що $|z_i| > 1$. Якщо умова порушується, відкоригувати початкові значення шляхом проектування на область стаціонарності.
\end{enumerate}

\subsubsection{Забезпечення Обмежень}

Для забезпечення стаціонарності та оборотності під час ітераційної оптимізації:

\paragraph{Параметризація через часткові автокореляції.}

Використовуємо параметризацію Box-Jenkins через часткові автокореляції (PACF), що автоматично гарантує стаціонарність:
\begin{equation}
\label{eq:pacf_parameterization}
\phi_1, \ldots, \phi_p = \text{PACF}^{-1}(\alpha_1, \ldots, \alpha_p), \quad \alpha_i \in (-1, 1)
\end{equation}

Аналогічно для MA параметрів через перетворення Ансомба.

\paragraph{Проектування на допустимий простір.}

Якщо оновлений параметр $\boldsymbol{\theta}^{(k)}$ порушує обмеження, проектуємо його на найближчу допустиму точку:
\begin{equation}
\label{eq:projection}
\boldsymbol{\theta}^{(k)} \leftarrow \arg\min_{\tilde{\boldsymbol{\theta}} \in \Theta} \|\tilde{\boldsymbol{\theta}} - \boldsymbol{\theta}^{(k)}\|^2
\end{equation}

\subsubsection{Діагностика Залишків}

Після оцінювання параметрів, необхідно перевірити адекватність моделі через аналіз залишків:

\begin{enumerate}
    \item \textbf{Тест Люнга-Бокса} для автокореляції залишків:
    \begin{equation}
    \label{eq:ljung_box}
    Q(m) = n(n+2) \sum_{k=1}^{m} \frac{\hat{\rho}_k^2}{n-k} \sim \chi^2(m - p - q)
    \end{equation}
    де $\hat{\rho}_k$ --- вибіркова автокореляція залишків на лагу $k$.

    \item \textbf{Оцінка кумулянтів залишків:} Обчислити $\hat{\gamma}_3$ та $\hat{\gamma}_4$ для верифікації припущень про розподіл інновацій.

    \item \textbf{Візуальна діагностика:} ACF/PACF графіки, Q-Q plot, гістограма залишків.
\end{enumerate}

\subsubsection{Обчислювальна Стабільність}

Для забезпечення числової стабільності:

\begin{itemize}
    \item \textbf{Нормалізація ряду:} Віднімаємо середнє та ділимо на стандартне відхилення.

    \item \textbf{Регуляризація Гессіана:} Додаємо малу діагональну матрицю $\lambda \mathbf{I}$ до Гессіана для уникнення сингулярності.

    \item \textbf{Line search:} Використовуємо line search (backtracking) для забезпечення збільшення цільової функції на кожній ітерації.
\end{itemize}

% ============================================
% BIBLIOGRAPHY (Placeholder)
% ============================================
\bibliographystyle{plain}
\bibliography{references}

% Note: Create references.bib file with all citations

\end{document}
